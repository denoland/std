# Tasks

- [ ] **Define the evals that will be used to test the definitions**

- [ ] **Define and Explain Asset Issuance**

  - Define asset issuance in the context of the Dreamcatcher Platform.
  - Explain the process of creating and distributing new [Assets] and [Tokens]
    within the platform.
  - Include key concepts like initial creation, distribution mechanisms, and how
    the [Attribution Algorithm] manages newly issued assets.

- [ ] **Clarify the Meaning of 'Bed Rock'**

  - Determine if 'bed rock' is synonymous with 'definitions' in this context.
  - Identify any differences between 'bed rock' and 'definitions'.
  - Update documentation to reflect the accurate meaning and usage of 'bed
    rock'.

- [ ] **Address Definition Drift from Common Usage**

  - Identify the risk of developing specialized or altered meanings of common
    words through prolonged dictionary work.
  - Compare our usage of terms against standard dictionary definitions.
  - Document where our definitions intentionally differ from common usage and
    why.
  - Create guidelines for when to use specialized versus common definitions.
  - Consider the impact on collaboration when others assume common definitions.

- [ ] **Review Definitions Against Standard English**

  - Compare all defined terms against authoritative English dictionaries
    (Oxford, Merriam-Webster, etc.).
  - Identify cases where our definitions conflict with or deviate from standard
    meanings.
  - Document the rationale for any necessary deviations from standard
    definitions.
  - Ensure specialized terms build upon rather than contradict common meanings.
  - Add clarifying notes where our usage extends or refines standard
    definitions.
  - Update documentation to acknowledge relationships to standard meanings.

- [ ] **Create Definitions NAPP with Evaluations**

  - Convert existing definitions into a structured NAPP format
  - Implement evaluation metrics to test definition effectiveness:
    - Test bot comprehension when using definitions as context
    - Measure consistency of bot responses across different prompts
    - Evaluate accuracy of bot interpretations against intended meanings
    - Track definition drift through automated testing
  - Implement automated testing pipeline for continuous definition validation
  - Generate reports highlighting areas where definitions need refinement
  - Build feedback loop to improve definitions based on evaluation results

- [ ] **Document Core Artifact Programming Features**

  - Identify fundamental execution capabilities needed but not in definitions:
    - File/directory manipulation patterns
    - Control flow structures (loops, conditionals, etc.)
    - Data structure operations
    - Multi-file editing and coordination
    - Error handling patterns
    - Resource management
  - Create user stories showing how these features enable platform capabilities
  - Map each feature to practical platform use cases

- [ ] **Define what 'complete correct coherent' means in the context of the
      definitions**
