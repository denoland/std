# Conversation
URL: https://chatgpt.com/share/67622a65-26f8-800b-b280-033fed5fb64e

### Message ID: f1e36b26-4af2-4af9-9572-f5c74281355b
**Author**: system

**Content:**



---

### Message ID: ec0d6b27-8088-4401-aefc-c0d4593923d4
**Author**: user

**Content:**

Original custom instructions no longer available

---

### Message ID: aaa26b34-3ede-4254-9e41-8d4abeae8376
**Author**: user

**Content:**

can you make me a ts file to use endo, running on nodejs, where I can give it a url for a typescript module, and it will be able to download that code and everything it depends on, then run it in a ses compartment

---

### Message ID: 9bbffdce-f1bb-40af-80fd-2ee3455fdb6d
**Author**: tool

**Content:**

**Crafting a secure environment**

I’m focusing on creating a TypeScript file with Endo in a SES compartment on Node.js, using ES6 modules and arrow functions.

**Building the process**

I’m gathering info on using Endo to run TypeScript code from a URL in a SES compartment, importing necessary Endo packages, and ensuring the JavaScript environment is in SES mode.

**Setting up the environment**

I’m preparing an environment for isolated execution by importing necessary Endo packages, setting up a new compartment, and evaluating code from a URL within this compartment.

**Gathering insights**

I’m organizing the TypeScript file to load code from a URL and run it in a Node.js environment using Endo, ensuring it adheres to ES6 modules and arrow functions.

**Fetching and running**

I’m thinking through how to fetch code from a URL, utilize `@endo/lockdown`, and create a custom read function to ensure the code runs in a SES compartment.

**Setting up a fetch mechanism**

I’m configuring a `fetch` function to retrieve code from a URL, ensuring it’s integrated with `loadLocation` for loading modules in a SES compartment on Node.js.

**Setting up a fetch mechanism**

Thinking about how to set up a fetch function to retrieve code from a URL, ensuring it integrates smoothly with `loadLocation` for module loading in a SES compartment on Node.js.

**Crafting a streamlined snippet**

I'm mapping out a minimal TypeScript snippet to fetch code from a URL and execute it in a SES compartment on Node.js, ensuring it aligns with the user's preferences.

**Fetching code**

I’m creating a minimal TypeScript snippet to fetch code from a URL and run it in a SES compartment on Node.js, including error handling and isolation setup.

---

### Message ID: b4ec97f0-2658-46e2-9a70-e5c57ad9da9e
**Author**: assistant

**Content:**

```typescript
// run-remote-module.ts
import 'ses';
import fetch from 'node-fetch';
import { makeImporter } from '@endo/compartment-mapper';

// Lock down the environment before anything else
lockdown({ errorTaming: 'unsafe', stackFiltering: 'verbose' });

const loadAndRun = async (moduleURL: string) => {
  const read = async (url: string): Promise<string> => {
    const res = await fetch(url);
    if (!res.ok) throw new Error(`Failed to fetch ${url}: ${res.statusText}`);
    return res.text();
  };

  const importer = makeImporter({
    read,
    resolve: (spec: string, ref: string) => new URL(spec, ref).toString(),
    makeImportHook: (srcSpec: string) => (specifier: string) =>
      importer.import(specifier, srcSpec),
  });

  const compartment = new Compartment({});
  const { namespace } = await importer.import(moduleURL, 'file:///');
  // namespace now holds the exported bindings from the remote module
  console.log(namespace);
};

loadAndRun('https://example.com/path/to/yourModule.ts').catch(console.error);
```

---

### Message ID: aaa209ea-66e5-4695-9272-c28dc109f250
**Author**: user

**Content:**

makeImporter isn't a valid export.  Here are the docs for the @endo/compartment-mapper module:

# Compartment mapper

The compartment mapper builds _compartment maps_ for Node.js style
applications, finding their dependencies and describing how to create
[Compartments][] for each package in the application.

Creating a compartment map for a Node.js application allows us to harness
the SES module loader to encapsulate each dependency and grant the least
necessary authority to each third-party package, mitigating prototype pollution
attacks and some supply chain attacks.
Since most Node.js packages do not modify objects in global scope,
many libraries and applications work in Compartments without modification.

The `importLocation` function runs a compartmentalized application off the file
system.
The `globals` are properties to add to the `globalThis` in the global scope
of the application's main package compartment.
The `modules` are built-in modules to grant the application's main package
compartment.

```js
import fs from "fs";
import { importLocation } from "@endo/compartment-mapper";

// ...

const modules = { fs };
const globals = { console };

const read = async location =>
  fs.promises.readFile(new URL(location).pathname);

const { namespace } = await importLocation(
  read,
  moduleLocation,
  {
    globals,
    modules
  }
);
```

The compartment mapper does nothing to arrange for the realm to be frozen.
The application using the compartment mapper is responsible for applying the
[SES] shim (if necessary) and calling `lockdown` to freeze the realm (if
necessary).
The compartment mapper is also not coupled specifically to Node.js IO and does
not import any powerful modules like `fs`.
The user must provide `read` and `write` functions from whatever IO powers they
have. These powers can be provided as individual functions or as objects
carrying functions. `ReadPowers` has optional functions which can be used to
unlock compatibility features. When `fileURLToPath` is available, `__dirname`
and `__filename` will be provided to CJS modules. If `requireResolve` is
available, it will be called whenever a CJS module calls `require.resolve()`.

```js
type ReadPowers = {
  read: (location: string) => Promise<Uint8Array>,
  canonical: (location: string) => Promise<string>,
  computeSha512: { (bytes: Uint8Array) => string }?,
  fileURLToPath: { (url: string | URL) => string }?,
  pathToFileURL: { (path: string) => URL }?,
  requireResolve: { (from: string, request: string, options?: {}) => string }?
}
```

> TODO
>
> A future version will allow application authors to distribute their choices
> of globals and built-in modules to third-party packages within the
> application, as with [LavaMoat].

The `importLocation` function uses `loadLocation`.
Using `loadLocation` directly allows for deferred execution or multiple runs
with different globals or modules in the same process.
Calling `loadLocation` returns an `Application` object with an
`import({ globals?, modules? })` method.

Use `writeArchive` to capture an application in an archival format.
Archives are `zip` files with a `compartment-map.json` manifest file.

```js
import fs from "fs";
import { writeArchive } from "@endo/compartment-mapper";

const read = async location =>
  fs.promises.readFile(new URL(location).pathname);
const write = async (location, content) =>
  fs.promises.writeFile(new URL(location).pathname, content);

await writeArchive(
  write,
  read,
  new URL('app.zip', import.meta.url).toString(), // the archive to write
  new URL('app.js', import.meta.url).toString() // the application to capture
);
```

The `writeArchive` function uses `makeArchive`.
Using `makeArchive` directly gives you the archive bytes.

Use `importArchive` to run an application from an archive.
Note the similarity to `importLocation`.

```js
import fs from "fs";
import { importArchive } from "@endo/compartment-mapper";

// ...

const modules = { fs };
const globals = { console };

const read = async location =>
  fs.promises.readFile(new URL(location).pathname);

const { namespace } = await importArchive(
  read,
  archiveLocation,
  {
    globals,
    modules
  }
);
```

The `importArchive` function composes `loadArchive` and `parseArchive`.
Use `loadArchive` to defer execution or run multiple times with varying
globals.
Use `parseArchive` to construct a runner from the bytes of an archive.
The `loadArchive` and `parseArchive` functions return an `Application`
object with an `import({ globals?, modules? })` method.

`loadArchive` and `parseArchive` do not run the archived program,
so they can be used to check the hash of a program without running it.

# Package Descriptors

The compartment mapper uses [Compartments], one for each Node.js package your
application needs.
The compartment mapper generates a compartment graph from Node.js packaged
module descriptors: the `package.json` files of the application and all its
dependencies.
Consequently, an application must have a `package.json`.

Each package has its own descriptor, `package.json`.
Some standard properties of the descriptor are relevant and used by a
compartment map.

* `name`
* `type`
* `main`
* `exports`
* `browser`
* `dependencies`
* `files`

The compartment map will contain one compartment for each `package.json`
necessary to build the application.
Like Node.js, the compartment mapper trusts the package manager to arrange the
packages such that a satisfactory version of every package's dependencies rests
in a parent directory, under `node_modules`.

The `main`, `browser`, and `exports` properties determine the modules each
package exports to other compartments.

The `exports` property describes [package entry points][] and can be influenced
by build _conditions_.
Currently, the only conditions supported by the compartment mapper are
`import`, `browser`, and `endo`.
The `imports` condition indicates that the module map should use ESM modules
over CommonJS modules or other variants, and `endo`.
The `browser` condition also draws in the `browser` property from
`package.json` instead of `main`.
The `endo` condition only indicates that this tool is in use.

If no `exports` apply to the root of the compartment namespace (`"."`),
the `main` property serves as a default.

> TODO
>
> A future version may also respect the `imports` property.

> TODO
>
> A future version may also respect wildcard patterns in `exports` and
> `imports`.

The `files` property indicates all of the files in the package that
should be vended out to applications.
The file set implicitly includes all `**.js`, `**.mjs`, and `**.cjs` files.
The file set implicitly excludes anything under `node_modules`.

With the compartment mapper, just as in Node.js, a module specifier that has no
extension may refer either to the file with the `js` extension, or if that file
does not exist, to the `index.js` file in the directory with the same name.

> TODO
>
> The compartment mapper does not yet do anything with the `files` globs but a
> future version of the compartment mapper will collect these in archives.
> The compartment mapper should eventually provide the means for any
> compartment to access its own files using an attenuated `fs` module or
> `fetch` global, in conjunction with usable values for `import.meta.url` in
> ECMAScript modules or `__dirname` and `__filename` in CommonJS modules.

## Language Extensions

Officially beginning with Node.js 14, Node.js treats `.mjs` files as ECMAScript
modules and `.cjs` files as CommonJS modules.
The `.js` extension indicates a CommonJS module by default, to maintain
backward compatibility.
However, packages that have a `type` property that explicitly says `module`
will treat a `.js` file as an ECMAScript module.

Many Node.js applications using CommonJS modules expect to be able to `require`
a JSON file like `package.json`.
The compartment mapper supports loading JSON modules from any type of module.
As of Node.js 14, Node does not support importing JSON using ECMAScript
`import` directives, so using this feature may limit compatibility with the
Node.js platform.

The compartment mapper supports loading CommonJS modules from ECMAScript
modules as well as ECMAScript modules importing CommonJS modules.
This presumes that the CommonJS modules exclusively use `require` calls with a
single string argument, where `require` is not lexically bound, to declare
their shallow dependencies, so that these modules and their transitive
dependencies can be loaded before any module executes.
As of Node.js 14, Node does not support loading ECMAScript modules from
CommonJS modules, so using this feature may limit compatibility with the
Node.js platform.

The compartment mapper supports language plugins.
The languages supported by default are:

- `mjs` for ECMAScript modules,
- `cjs` for CommonJS modules,
- `json` for JSON modules,
- `text` for UTF-8 encoded text files,
- `bytes` for any file, exporting a `Uint8Array` as `default`,
- `pre-mjs-json` for pre-compiled ECMAScript modules captured as JSON in
  archives, and
- `pre-cjs-json` for pre-compiled CommonJS modules captured as JSON in
  archives.

The compartment mapper accepts extensions to this set of languages with
the `parserForLanguage` option supported by many functions.
See `src/types/external.ts` for the type and expected behavior for
parsers.

These language identifiers are keys for the `moduleTransforms` and
`syncModuleTransforms` options, which may map each language to a transform
function.
The language identifiers are also the values for a `languageForExtension`,
`moduleLanguageForExtension`, and `commonjsLanguageForExtension` options to
configure additional extension-to-language mappings for a module and its
transitive dependencies.

For any package that has `type` set to `"module"` in its `package.json`,
`moduleLangaugeForExtension` will precede `languageForExtension`.
Packages with `type` set to `"commonjs"` or simply not set,
`commonjsLanguageForExtension` will precede `languageForExtension`.
This provides an hook for mapping TypeScript's `.ts` to either `.cts` or
`.mts`.

The analogous `workspaceLanguageForExtension`,
`workspaceCommonjsLanguageForExtension`, and
`workspaceModuleLanguageForExtension` options apply more specifically for
packages that are not under a `node_modules` directory, indicating that they
are in the set of linked workspaces and have not been built or published to
npm.

In the scope any given package, the `parsers` property in `package.json` may
override the extension-to-language mapping.

```json
{
  "parsers": { "png": "bytes" }
}
```

> TODO
>
> The compartment mapper may elect to respect some properties specified for
> import maps.

> TODO
>
> A future version of the compartment mapper may add support for
> source-to-source translation in the scope of a package or compartment.
> This would be expressed in `package.json` using a property like
> `translate` that would contain a map from file extension
> to a module that exports a suitable translator.
>
> For browser applications, the compartment mapper would use the translator
> modules in two modes.
> During development, the compartment mapper would be able to load the
> translator in the client, with the `browser` condition.
> The compartment mapper would also be able to run the translator in a separate
> non-browser compartment during bundling, so the translator can be excluded
> from the production application and archived applications.

> TODO
>
> The compartment mapper may also add support for compartment map plugins that
> would recognize packages in `devDependencies` that need to introduce globals.
> For example, _packages_ that use JSX and a virtual DOM would be able to add a
> module-to-module translator and endow the compartment with the `h` the
> translated modules need.

# Source Maps

The `makeArchive`, `makeAndHashArchive`, and `writeArchive` tools can receive a
`sourceMapHook` as one of its options.
The `sourceMapHook` receives a source map `string` for every module it
archives, along with details `compartment`, `module`, `location`, and `sha512`.
The `compartment` is the fully-qualified file URL of the package root.
The `module` is the package-relative module specifier.
The `location` is the fully-qualified file URL of the module file.
The `sha512`, if present, was generated with the `computeSha512` power from the
generated module bytes.

The functions `importArchive`, `loadArchive`, and `parseArchive`
tools can receive a `computeSourceMapLocation` option that recives the same
details as above and must return a URL.
These will be appended to each module from the archive, for debugging purposes.

The `@endo/bundle-source` and `@endo/import-bundle` tools integrate source maps
for an end-to-end debugging experience.

# XS (experimental)

The Compartment Mapper can use native XS `Compartment` and `ModuleSource` under
certain conditions:

1. The application must be an XS script that was compiled with the `xs`
  package condition.
  This causes `ses`, `@endo/module-source`, and `@endo/import-bundle` to
  provide slightly different implementations that can fall through to native
  behavior.
2. The application must opt-in with the `__native__: true` option on any
  of the compartment mapper methods that import modules like `importLocation`
  and `importArchive`.

# Design

Each of the workflows the compartment mapper executes a portion of one sequence
of underlying internals.

* search (`search.js`): Scan the parent directories of a given `moduleLocation`
  until successfully finding and reading a `package.json` for the containing
  application.
* map compartments from Node.js packages (`node-modules.js`): Find and gather
  all the `package.json` files for the application's transitive dependencies.
  Use these to construct a compartment map describing how to construct a
  `Compartment` for each application package and how to link the modules each
  exports in the compartments that import them.
* load compartments (`archive.js`): Using `compartment.load`, or
  implicitly through `compartment.import`, create a module graph for the
  application's entire working set.
  When creating an archive, this does not execute any of the modules.
  The compartment mapper uses the compartments and a special `importHook` that
  records the text of every module the main module needed.
* import modules (`import.js`, `import-archive.js`): Actually execute the
  working set.

Around this sequence, we can enter late or depart early to store or retrieve an
archive.
The compartment mapper provides workflows that use `read` and `write` hooks
when interacting with a filesystem or work with the archive bytes directly.

This diagram represents the the workflows of each of the public methods like
`importLocation`.
Each column of pipes `|` is a workflow from top to bottom.
Each asterisk `*` denotes a step that is taken by that workflow.
The dotted lines `.'. : '.'` indicate carrying an archive file from the end of
one workflow to the beginning of another, either as bytes or a location.

In the diagram, "powers" refer to globals and built-in modules that may provide
capabilities to a compartment graph.
For `writeArchive` and `makeArchive`, these may be provided but will be ignored
since the application does not execute.

```
                 loadLocation  writeArchive
             importLocation |  | makeArchive
                          | |  | |
                          | |  | |      parseArchive
                          | |  | |      | loadArchive
                          | |  | |      | | importArchive
                          | |  | |      | | |...
               search ->  * *  * *      | |'| . '
     map compartments ->  * *  * *   .'.| | |' : :
         read archive ->  |    | |  '   | * *  : :
       unpack archive ->  |    | |  :   * * *  : :
assemble compartments ->  *    * *  :       *  : : <- powers
    load compartments ->  *    * *  :       *  : :
       import modules ->  *    | |  :       *  : :
         pack archive ->       * *  '          : :
        write archive ->       * '.' <- data   : :
                               '..............'  : <- files
                                '...............'
```

# Compartment maps

The compartment mapper works by generating a _compartment map_ from your
application workspace and all of the `node_modules` it needs.
A compartment map is similar to a lock file because it collects information
from all of the installed modules.
A compartment map describes how to construct compartments for each
package in your application and link their module namespaces.

The compartment map shape:

```ts
// CompartmentMap describes how to prepare compartments
// to run an application.
type CompartmentMap = {
  tags: Conditions,
  entry: Entry,
  compartments: Record<CompartmentName, Compartment>,
  realms: Record<RealmName, Realm>, // TODO
};

// Conditions influence which modules are selected
// to represent the implementation of various modules.
// These may include terms like "browser", meaning
// each compartment uses the implementation of each
// module suitable for use in a browser environment.
type Conditions = Array<Condition>;
type Condition = string;

// Entry is a reference to the module that is the module to initially import.
type Entry = CompartmentModule;

// CompartmentName is an arbitrary string to name
// a compartment for purposes of inter-compartment linkage.
type CompartmentName = string;

// Compartment describes where to find the modules
// for a compartment and how to link the compartment
// to modules in other compartments, or to built-in modules.
type Compartment = {
  location: Location,
  modules: ModuleMap,
  parsers: ParserMap,
  types: ModuleParserMap,
  scopes: ScopeMap,
  // The name of the realm to run the compartment within.
  // The default is a single frozen realm that has no name.
  realm: RealmName? // TODO
};

// Location is the URL relative to the compartment-map.json's
// containing location to the compartment's files.
type Location = string;

// ModuleMap describes modules available in the compartment
// that do not correspond to source files in the same compartment.
type ModuleMap = Record<InternalModuleSpecifier, Module>;

// Module describes a module in a compartment.
type Module = CompartmentModule | FileModule | ExitModule;

// CompartmentModule describes a module that isn't in the same
// compartment and how to introduce it to the compartment's
// module namespace.
type CompartmentModule = {
  // The name of the foreign compartment:
  // TODO an absent compartment name may imply either
  // that the module is an internal alias of the
  // same compartment, or given by the user.
  compartment: CompartmentName?,
  // The name of the module in the foreign compartment's
  // module namespace:
  module: ExternalModuleSpecifier?,
};

// FileLocation is a URL for a module's file relative to the location of the
// containing compartment.
type FileLocation = string

// FileModule is a module from a file.
// When loading modules off a file system (src/import.js), the assembler
// does not need any explicit FileModules, and instead relies on the
// compartment to declare a ParserMap and optionally ModuleParserMap and
// ScopeMap.
// The compartment mapper provides a Compartment importHook and moduleMapHook
// that will search the filesystem for candidate module files and infer the
// type from the extension when necessary.
type FileModule = {
   location: FileLocation,
   parser: Parser,
};

// ExitName is the name of a built-in module, to be threaded in from the
// modules passed to the module executor.
type ExitName = string;

// ExitModule refers to a module that comes from outside the compartment map.
type ExitModule = {
  exit: ExitName
};

// InternalModuleSpecifier is the module specifier
// in the namespace of the native compartment.
type InternalModuleSpecifier = string;

// ExternalModuleSpecifier is the module specifier
// in the namespace of the foreign compartment.
type ExternalModuleSpecifier = string;

// ParserMap indicates which parser to use to construct module sources
// from sources, for each supported file extension.
// For parity with Node.js, a package with `"type": "module"` in its
// `package.json` would have a parser map of `{"js": "mjs", "cjs": "cjs",
// "mjs": "mjs"}`.
// If `"module"` is not defined in package.json, the legacy parser map // is
// `{"js": "cjs", "cjs": "cjs", "mjs": "mjs"}`.
// The compartment mapper adds `{"json": "json"}` for good measure in both
// cases, although Node.js (as of version 0.14.5) does not support importing
// JSON modules from ESM.
type ParserMap = Record<Extension, Parser>;

// Extension is a file extension such as "js" for "main.js" or "" for "README".
type Extension = string;

// Parser is a union of built-in parsers for module sources.
// "mjs" corresponds to ECMAScript modules.
// "cjs" corresponds to CommonJS modules.
// "json" corresponds to JSON.
type Parser = "mjs" | "cjs" | "json";

// ModuleParserMap is a table of internal module specifiers
// to the parser that should be used, regardless of that module's
// extension.
// Node.js allows the "module" property in package.json to denote
// a file that is an ECMAScript module, regardless of its extension.
// This is the mechanism that allows the compartment mapper to respect that
// behavior.
type ModuleParserMap = Record<InternalModuleSpecifier, Parser>;

// ScopeMap is a map from internal module specifier prefixes
// like "dependency" or "@organization/dependency" to another
// compartment.
// The compartment mapper uses this to build a moduleMapHook that can dynamically
// generate entries for a compartment's moduleMap into Node.js packages that do
// not explicitly state their "exports".
// For these modules, any specifier under that prefix corresponds
// to a link into some internal module of the foreign compartment.
>> When the compartment mapper creates an archive, it captures all of the Modules
>> explicitly and erases the scopes entry.
type ScopeMap = Record<InternalModuleSpecifier, Scope>;

// Scope describes the compartment to use for all ad-hoc
// entries in the compartment's module map.
type Scope = {
  compartment: CompartmentName
};


// TODO everything hereafter...

// Realm describes another realm to contain one or more
// compartments.
// The default realm is frozen by lockdown with no
// powerful references.
type Realm = {
  // TODO lockdown options
};

// RealmName is an arbitrary identifier for realms
// for reference from any Compartment description.
// No names are reserved; the default realm has no name.
type RealmName = string;

// ModuleParameter indicates that the module does not come from
// another compartment but must be passed expressly into the
// application by the user.
// For example, the Node.js `fs` built-in module provides
// powers that must be expressly granted to an application
// and may be attenuated or limited by the compartment mapper on behalf of the
// user.
// The string value is the name of the module to be provided
// in the application's given module map.
type ModuleParameter = string;
```

# Compartment map policy

The `policy` option accepted by the compartment-mapper API methods provides means to narrow down the endowments passed to each compartment independently.  
The rules defined by policy get preserved in the compartment map and enforced in the application. To explore how policies work, see [Policy Demo].

The shape of the `policy` object is based on `policy.json` from LavaMoat. MetaMask's [LavaMoat] generates a `policy.json` file that serves the same purposes, using a tool called TOFU: _trust on first use_.

> TODO
>
> Endo policy support is intended to reach parity with LavaMoat's policy.json.
> Policy generation may be ported to Endo.


  [LavaMoat]: https://github.com/LavaMoat/lavamoat
  [Compartments]: ../ses/README.md#compartment
  [Policy Demo]: ./demo/policy/README.md
  [package entry points]: https://nodejs.org/api/esm.html#esm_package_entry_points

---

### Message ID: ebf6d6f3-209e-451c-b85a-06d3d6492b9b
**Author**: tool

**Content:**

**Piecing together remote imports**

I’m working through a TypeScript snippet to fetch a remote module and run it in a SES compartment. The code needs `lockdown()` and `importLocation` from `@endo/compartment-mapper`.

**Setting up a fetch function**

I’m establishing a fetch-based `read` function for `importLocation`. The function needs to convert fetch results to `Uint8Array`, and globals and modules must be specified, possibly including `console` and an empty modules object.

**Navigating module handling**

Interestingly enough, `@endo/compartment-mapper` doesn't naturally handle TypeScript modules. To solve this, I'd use a transform or translator, assuming the given file is `.js` or `.mjs`.

**Importing and running**

The goal is to use `importLocation` with a custom fetch function to bring in a TypeScript file from a URL. This method will ensure smooth execution in a SES compartment.

**Ensuring secure execution**

I'm preparing to address `read` with `Promise<Uint8Array>`, utilizing `await fetch(...).arrayBuffer()` and `new Uint8Array(await res.arrayBuffer())`. It's worth noting the inclusion of `lockdown()` from `ses`.

**Setting up the snippet**

I’m defining a TypeScript script to fetch and execute a remote module in a SES environment using `@endo/compartment-mapper`. The `read` function employs `fetch` to handle data retrieval.

**Adjusting language handling**

I’m thinking through how to handle TypeScript files by configuring `` in the `package.json` file, ensuring they are processed correctly. This would typically involve setting up TypeScript to compile to JavaScript.

**Fetch and translate**

I’m showing how to fetch a TypeScript file, translate it to JavaScript with `mjs` extensions, and run it in a SES environment using `@endo/compartment-mapper`.

---

### Message ID: 69448896-7cad-4321-b3f8-d3e061005700
**Author**: assistant

**Content:**

```typescript
// run-remote-module.ts
import 'ses';
import fetch from 'node-fetch';
import { importLocation } from '@endo/compartment-mapper';

// Lock down the environment
lockdown({ errorTaming: 'unsafe', stackFiltering: 'verbose' });

const loadAndRun = async (moduleURL: string) => {
  // We'll treat the given module URL as part of a virtual package where:
  // - A synthetic package.json is served at the same origin
  // - The module itself is the "main" entry
  const packageURL = new URL('./package.json', moduleURL).toString();

  const read = async (location: string): Promise<Uint8Array> => {
    if (location === packageURL) {
      // Minimal package.json: treat all JS/TS as ESM
      // We set main to the TS file and type=module so .ts is treated as ES modules.
      const pkg = {
        name: "remote-module",
        type: "module",
        main: new URL(moduleURL).pathname.replace(/^\/+/, '')
      };
      return new TextEncoder().encode(JSON.stringify(pkg));
    } else {
      // Fetch any module file (ts, js, etc.) from the remote source
      const res = await fetch(location);
      if (!res.ok) {
        throw new Error(`Failed to fetch ${location}: ${res.statusText}`);
      }
      const content = await res.arrayBuffer();
      return new Uint8Array(content);
    }
  };

  // Treat .ts as ESM (mjs)
  const languageForExtension = { ts: 'mjs' };

  // Provide limited globals/modules
  const globals = { console };
  const modules = {};

  // Import the remote module as if it were a local app entry point
  const { namespace } = await importLocation(
    read,
    moduleURL,
    { globals, modules, languageForExtension }
  );

  console.log(namespace);
};

loadAndRun('https://example.com/yourModule.ts').catch(err => {
  console.error(err);
  process.exit(1);
});
```

---

### Message ID: aaa2022e-a366-421e-b547-d0f19a6721b7
**Author**: user

**Content:**

additionally, here are all the docs from all the @endo packages.  Please see if they can help you improve at all:

-----BEGIN FILE base64/README.md-----
# base64

Base64 is a JavaScript package that encodes and decodes
[Base64](https://en.wikipedia.org/wiki/Base64) between strings and
`Uint8Array`s.

Base64 exports TypeScript definitions and is suitable for both web and Node.js.

## Install

```sh
npm install @endo/base64
```

## Usage

```js
import { encodeBase64, decodeBase64 } from '@endo/base64';

const string = encodeBase64(bytes);
const bytes = decodeBase64(string);
```

-----END FILE base64/README.md-----
-----BEGIN FILE bundle-source/README.md-----
# Bundle Source

This package creates source bundles from ES Modules, compatible with Endo
applications, Agoric contracts, and SwingSet vats.

To bundle a program that enters at `program.js` from the command line, use the
`bundle-source` tool:

```console
> yarn bundle-source --cache-json bundles program.js program
```

To do the same programmatically:

```js
import 'ses';
import bundleSource from '@endo/bundle-source';
import url from 'url';

const sourceBundleURL = new URL('program.js', import.meta.url);
const sourceBundlePath = url.fileURLToPath(sourceBundleURL);
const sourceBundleP = bundleSource(sourceBundlePath);
```

…to get a promise for a source bundle, that resolves after reading the
named sources and bundling them into a form that vats can load, as indicated
by the `moduleFormat` below.

The resulting bundle is suitable for use with `@endo/import-bundle`.
The default format is of a bundle is `"endoZipBase64"`.

## Conditions

Node.js introduced [conditions](https://nodejs.org/api/packages.html#conditional-exports).
The `--condition` and `-C` flags accordingly influence `bundle-source` module
resolution decisions.

The `browser` condition additionally implies the selection of the `browser`
entry instead of `main` in `package.json`, if not overridden by explicit
`exports`.

The `development` condition additionally implies that the bundle may import
`devDependencies` from the package containing the entry module.

## Comment Elision

The `--elide-comments (`-e`) flag with `--format` (`-f`) `endoScript` or
`endoZipBase64` (default) causes the bundler to blank out the interior of
comments, without compromising line or column number cursor advancement.
This can reduce bundle size without harming the debug experience any more than
other transforms.

Comment elision preserves `/*! slashasterbang /` comments and JSDoc comments
with `@preserve`, `@copyright`, `@license` pragmas or the Internet Explorer
`@cc_on` pragma.

Comment elision does not strip comments entirely.
The syntax to begin or end comments remains.

## TypeScript type erasure

TypeScript modules with the `.ts`, `.mts`, and `.cts` extensions in
packages that are not under a `node_modules` directory are automatically
converted to JavaScript through type erasure using
[`ts-blank-space`](https://bloomberg.github.io/ts-blank-space/).

This will not function for packages that are published as their original
TypeScript sources, as is consistent with `node
--experimental-strip-types`.
This will also not function properly for TypeScript modules that have
[runtime impacting syntax](https://github.com/bloomberg/ts-blank-space/blob/main/docs/unsupported_syntax.md),
such as `enum`.

This also does not support importing a `.ts` file using the corresponding
imaginary, generated module with a `.js` extension.
Use this feature in conjunction with
[`--allowImportingTsExtensions`](https://www.typescriptlang.org/tsconfig/#allowImportingTsExtensions).

## Source maps

With the `moduleFormat` of `endoZipBase64`, the bundler can generate source
maps but does not include them in the bundle itself.
Use the `cacheSourceMaps` option to render source maps into a per-user per-host
cache.

The `@endo/import-bundle` utility can add references to these generated
source maps when it unpacks a bundle, provided a suitable
`computeSourceMapLocation` power, like the one provided by
`@endo/import-bundle/source-map-node.js`.

```js
import 'ses';
import { importBundle } from '@endo/import-bundle';
import { computeSourceMapLocation } from '@endo/import-bundle/source-map-node.js';
await importBundle(
  bundle,
  { endowments: { console } },
  { computeSourceMapLocation },
);
```

Use the `@endo/cli` to find your cache.

```console
> yarn add -D @endo/cli
> yarn endo where cache
```

Use the `XDG_CACHE_HOME` environment variable to override the default location
of caches in general.
The caches will be in `endo/source-map` and `endo/source-map-track`.
The former is a content-address-store keyed on the SHA-512 of each bundled
module file.
The latter is a location-address-store keyed on the SHA-512 of the fully
qualified path of the module source, indicating the last known bundle hash.
The bundler uses the tracker to ensure that the cache only contains one source
map for every physical module.
It is not yet quite clever enough to collect source maps for sources that do
not exist.

## getExport moduleFormat

The most primitive `moduleFormat` is the `"getExport"` format.
It generates source like:

```js
function getExport() {
  let exports = {};
  const module = { exports };
  // CommonJS source translated from the inputs.
  ...
  return module.exports;
}
```

To evaluate it and obtain the resulting module namespace, you need to endow
a `require` function to resolve external imports.

## nestedEvaluate moduleFormat

This is logically similar to the `getExport` format, except that the code
may additionally depend upon a `nestedEvaluate(src)` function to be used
to evaluate submodules in the same context as the parent function.

The advantage of this format is that it helps preserve the filenames within
the bundle in the event of any stack traces.

Also, the toplevel `getExport(filePrefix = "/bundled-source")` accepts an
optional `filePrefix` argument (which is prepended to relative paths for the
bundled files) in order to help give context to stack traces.

## endoZipBase64 moduleFormat

An Endo (zip, base64) bundle is an object with properties:

- `moduleFormat` is `"endoZipBase64"`
- `endoZipBase64` is a base 64 encoded zip file.
- `endoZipBase64Sha512`, if present, is the SHA-512 of the
  `compartment-map.json` file inside the `endoZipBase64` archive.
  If the `compartment-map.json` includes the SHA-512 of every module, this is
  sufficient as a hash of the bundled application for checking its integrity
  and is consistent regardless of whether the program is extracted from the
  archive.

To inspect the contents of a bundle in a JSON file:

```
jq -r .endoZipBase64 | base64 -d | xxd | less
```

To extract the contents:

```
jq -r .endoZipBase64 | base64 -d > bundle.zip
unzip bundle.zip -d bundle
```

Inside the zip file, the `compartment-map.json` expresses the entire linkage of
the bundled program starting at its entry module, with explicitly marked "exit"
modules (host modules that must be endowed).

The compartment map then names all of its compartments, and within each
compartment, specifies each module that will be evaluated in that compartment.
These indicate the path within the archive of the physical text of the module.
The `parser` indicates how `importBundle` or the equivalent Compartment Mapper
utilities will interpret the physical text of the module.

To avoid entraining large dependencies and a slow precompilation step, modules
in a bundle are currently precompiled, so instead of finding source text, you
will find a JSON record describing the bindings and behavior of the module,
including code that is similar to the source but not identical.

The bundle may have any of these `"parser"` properties:

- `pre-mjs-json`: precompiled ESM
- `pre-cjs-json`: precompiled CommonJS
- `json`: raw JSON (exports the corresponding value as `default`)
- `text`: UTF-8 encoded text (exports the corresponding `string` as `default`)
- `bytes`: bytes (exports the corresponding `Uint8Array` as `default`)

The JSON of a `pre-mjs-json` module will have all the properties of an object
generated with `StaticModuleRecord` from `@endo/static-module-record`, but
particularly:

- `__syncModuleProgram__`: the code, which has been transformed from the ESM
  source to a program that a compartment can evaluate and bind to other ESM
  modules, and also had certain censorship-evasion transforms applied.

So, to extract the source-similar program for visual inspection:

```
jq -r .__syncModuleProgram module.js > module.source.js
```


-----END FILE bundle-source/README.md-----
-----BEGIN FILE captp/README.md-----
# `@endo/captp`

A minimal CapTP implementation leveraging Agoric's published modules.

## Usage

NOTE: `myconn` below is not part of the CapTP library, it represents a connection
object that you have created where `makeCapTP` is called on both sides of the
connection, passing in the function to send a JSON-able object on the connection, and returning
a `dispatch` function to receive a decoded JSON object from the connection.

```js
import { E, makeCapTP } from '@endo/captp';

// Create a message dispatcher and bootstrap.
// Messages on myconn are exchanged with JSON-able objects.
const { dispatch, getBootstrap, abort } = makeCapTP('myid', myconn.send, myBootstrap);
myconn.onReceive = obj => dispatch(obj);

// Get the remote's bootstrap object and call a remote method.
E(getBootstrap()).method(args).then(res => console.log('got res', res));

// Tear down the CapTP connection if it fails (e.g. connection is closed).
abort(Error('Connection aborted by user.'));
```

## Loopback

The `makeLoopback()` function creates an async barrier between "near" and "far"
objects.  This is useful for testing and isolation within the same address
space.

## TrapCaps

In addition to the normal CapTP facilities, this library also has the notion of
"TrapCaps", which enable a "guest" endpoint to call a "host" object (which may
resolve an answer promise at its convenience), but the guest synchronously
blocks until it receives the resolved answer.

This is a specialized and advanced use case, not for mutually-suspicious CapTP
parties, but instead for clear "guest"/"host" relationship, such as user-space
code and synchronous devices.

1. Supply the `trapHost` and `trapGuest` protocol implementation (such as the
   one based on `SharedArrayBuffers` in `src/atomics.js`) to the host and guest
   `makeCapTP` calls.
2. On the host side, use the returned `makeTrapHandler(target)` to mark a target
   as synchronous-enabled.
3. On the guest side, use the returned `Trap(target)` proxy maker much like
   `E(target)`, but it will return a synchronous result.  `Trap` will throw an
   error if `target` was not marked as a TrapHandler by the host.

To understand how `trapHost` and `trapGuest` relate, consider the `trapHost` as
a maker of AsyncIterators which don't return any useful value.  These specific
iterators are used to drive the transfer of serialized data back to the guest.

`trapGuest` receives arguments to describe the specific trap request, including
`startTrap()` which sends data to the host to perform the actual work of the
trap.  The returned (synchronous) iterator from `startTrap()` drives the async
iterator of the host until it fully transfers the trap results to the guest, and
the guest unblocks.

The Loopback implementation provides partial support for TrapCaps, except it
cannot unwrap promises.  Loopback TrapHandlers must return synchronously, or an
exception will be thrown.

-----END FILE captp/README.md-----
-----BEGIN FILE check-bundle/README.md-----
# check-bundle

`checkBundle` verifies the integrity of a bundle, inspects all of its internal hashes and its one external hash.
`checkBundle` verifies the internal consistency, completeness, coherence, and conciseness (no extra files) of the bundle.
The function returns a rejected promise if the bundle fails the check.

```js
const bundle = await bundleSource('path/to/bundle.js');
// 'bundle' is JSON-serializable
await checkBundle(bundle);
```

This must be run in an Endo environment. To run on Node.js, import `@endo/init` before importing `@endo/import-bundle`.

-----END FILE check-bundle/README.md-----
-----BEGIN FILE cjs-module-analyzer/README.md-----

-----END FILE cjs-module-analyzer/README.md-----
-----BEGIN FILE cli/README.md-----
# Endo CLI

The Endo command line is a user interface for managing the Endo application
runner (daemon).
This includes managing the lifecycle of the daemon process.

-----END FILE cli/README.md-----
-----BEGIN FILE common/README.md-----
# `@endo/common`

A collection of common low level utilities.

Each of the utilities in this packages
- are low level in the sense of not depending on anything higher level than `ses`, `@endo/eventual-send`, and `@endo/promise-kit`. Many depend on nothing beyond plain old JavaScript.
- highly reusable, i.e., potentially useful many places.
- sufficiently general that it would be awkward to import from a more specialized package.
- can be explained and motivated without much external knowledge.

Each utility is in its own top-level source file, named after the main export of that utility. (This is often that file's only export.) The `package.json` also lists each as a distinct `"export":`. There is no `index.js` file that rolls them together. Thus, each importer must do a deep import of exactly the export it needs. Some implementations (bundlers, packagers) can thus do tree-shaking, omitted code that isn't reachable by imports.

Currently there are no `src/something.js` files. The only source files that would go in `src/` are those that do not represent separately exported utilities.

Generally each utility also has its own test file. (An exception is that `make-iterator.js` is indirectly but adequately tested by `test-make-array-iterator.js`).

See the doc-comments within the source file of each utility for documentation of that utility. Sometimes the associated test files also serve as informative examples.

-----END FILE common/README.md-----
-----BEGIN FILE compartment-mapper/README.md-----
# Compartment mapper

The compartment mapper builds _compartment maps_ for Node.js style
applications, finding their dependencies and describing how to create
[Compartments][] for each package in the application.

Creating a compartment map for a Node.js application allows us to harness
the SES module loader to encapsulate each dependency and grant the least
necessary authority to each third-party package, mitigating prototype pollution
attacks and some supply chain attacks.
Since most Node.js packages do not modify objects in global scope,
many libraries and applications work in Compartments without modification.

The `importLocation` function runs a compartmentalized application off the file
system.
The `globals` are properties to add to the `globalThis` in the global scope
of the application's main package compartment.
The `modules` are built-in modules to grant the application's main package
compartment.

```js
import fs from "fs";
import { importLocation } from "@endo/compartment-mapper";

// ...

const modules = { fs };
const globals = { console };

const read = async location =>
  fs.promises.readFile(new URL(location).pathname);

const { namespace } = await importLocation(
  read,
  moduleLocation,
  {
    globals,
    modules
  }
);
```

The compartment mapper does nothing to arrange for the realm to be frozen.
The application using the compartment mapper is responsible for applying the
[SES] shim (if necessary) and calling `lockdown` to freeze the realm (if
necessary).
The compartment mapper is also not coupled specifically to Node.js IO and does
not import any powerful modules like `fs`.
The user must provide `read` and `write` functions from whatever IO powers they
have. These powers can be provided as individual functions or as objects
carrying functions. `ReadPowers` has optional functions which can be used to
unlock compatibility features. When `fileURLToPath` is available, `__dirname`
and `__filename` will be provided to CJS modules. If `requireResolve` is
available, it will be called whenever a CJS module calls `require.resolve()`.

```js
type ReadPowers = {
  read: (location: string) => Promise<Uint8Array>,
  canonical: (location: string) => Promise<string>,
  computeSha512: { (bytes: Uint8Array) => string }?,
  fileURLToPath: { (url: string | URL) => string }?,
  pathToFileURL: { (path: string) => URL }?,
  requireResolve: { (from: string, request: string, options?: {}) => string }?
}
```

> TODO
>
> A future version will allow application authors to distribute their choices
> of globals and built-in modules to third-party packages within the
> application, as with [LavaMoat].

The `importLocation` function uses `loadLocation`.
Using `loadLocation` directly allows for deferred execution or multiple runs
with different globals or modules in the same process.
Calling `loadLocation` returns an `Application` object with an
`import({ globals?, modules? })` method.

Use `writeArchive` to capture an application in an archival format.
Archives are `zip` files with a `compartment-map.json` manifest file.

```js
import fs from "fs";
import { writeArchive } from "@endo/compartment-mapper";

const read = async location =>
  fs.promises.readFile(new URL(location).pathname);
const write = async (location, content) =>
  fs.promises.writeFile(new URL(location).pathname, content);

await writeArchive(
  write,
  read,
  new URL('app.zip', import.meta.url).toString(), // the archive to write
  new URL('app.js', import.meta.url).toString() // the application to capture
);
```

The `writeArchive` function uses `makeArchive`.
Using `makeArchive` directly gives you the archive bytes.

Use `importArchive` to run an application from an archive.
Note the similarity to `importLocation`.

```js
import fs from "fs";
import { importArchive } from "@endo/compartment-mapper";

// ...

const modules = { fs };
const globals = { console };

const read = async location =>
  fs.promises.readFile(new URL(location).pathname);

const { namespace } = await importArchive(
  read,
  archiveLocation,
  {
    globals,
    modules
  }
);
```

The `importArchive` function composes `loadArchive` and `parseArchive`.
Use `loadArchive` to defer execution or run multiple times with varying
globals.
Use `parseArchive` to construct a runner from the bytes of an archive.
The `loadArchive` and `parseArchive` functions return an `Application`
object with an `import({ globals?, modules? })` method.

`loadArchive` and `parseArchive` do not run the archived program,
so they can be used to check the hash of a program without running it.

# Package Descriptors

The compartment mapper uses [Compartments], one for each Node.js package your
application needs.
The compartment mapper generates a compartment graph from Node.js packaged
module descriptors: the `package.json` files of the application and all its
dependencies.
Consequently, an application must have a `package.json`.

Each package has its own descriptor, `package.json`.
Some standard properties of the descriptor are relevant and used by a
compartment map.

* `name`
* `type`
* `main`
* `exports`
* `browser`
* `dependencies`
* `files`

The compartment map will contain one compartment for each `package.json`
necessary to build the application.
Like Node.js, the compartment mapper trusts the package manager to arrange the
packages such that a satisfactory version of every package's dependencies rests
in a parent directory, under `node_modules`.

The `main`, `browser`, and `exports` properties determine the modules each
package exports to other compartments.

The `exports` property describes [package entry points][] and can be influenced
by build _conditions_.
Currently, the only conditions supported by the compartment mapper are
`import`, `browser`, and `endo`.
The `imports` condition indicates that the module map should use ESM modules
over CommonJS modules or other variants, and `endo`.
The `browser` condition also draws in the `browser` property from
`package.json` instead of `main`.
The `endo` condition only indicates that this tool is in use.

If no `exports` apply to the root of the compartment namespace (`"."`),
the `main` property serves as a default.

> TODO
>
> A future version may also respect the `imports` property.

> TODO
>
> A future version may also respect wildcard patterns in `exports` and
> `imports`.

The `files` property indicates all of the files in the package that
should be vended out to applications.
The file set implicitly includes all `**.js`, `**.mjs`, and `**.cjs` files.
The file set implicitly excludes anything under `node_modules`.

With the compartment mapper, just as in Node.js, a module specifier that has no
extension may refer either to the file with the `js` extension, or if that file
does not exist, to the `index.js` file in the directory with the same name.

> TODO
>
> The compartment mapper does not yet do anything with the `files` globs but a
> future version of the compartment mapper will collect these in archives.
> The compartment mapper should eventually provide the means for any
> compartment to access its own files using an attenuated `fs` module or
> `fetch` global, in conjunction with usable values for `import.meta.url` in
> ECMAScript modules or `__dirname` and `__filename` in CommonJS modules.

## Language Extensions

Officially beginning with Node.js 14, Node.js treats `.mjs` files as ECMAScript
modules and `.cjs` files as CommonJS modules.
The `.js` extension indicates a CommonJS module by default, to maintain
backward compatibility.
However, packages that have a `type` property that explicitly says `module`
will treat a `.js` file as an ECMAScript module.

Many Node.js applications using CommonJS modules expect to be able to `require`
a JSON file like `package.json`.
The compartment mapper supports loading JSON modules from any type of module.
As of Node.js 14, Node does not support importing JSON using ECMAScript
`import` directives, so using this feature may limit compatibility with the
Node.js platform.

The compartment mapper supports loading CommonJS modules from ECMAScript
modules as well as ECMAScript modules importing CommonJS modules.
This presumes that the CommonJS modules exclusively use `require` calls with a
single string argument, where `require` is not lexically bound, to declare
their shallow dependencies, so that these modules and their transitive
dependencies can be loaded before any module executes.
As of Node.js 14, Node does not support loading ECMAScript modules from
CommonJS modules, so using this feature may limit compatibility with the
Node.js platform.

The compartment mapper supports language plugins.
The languages supported by default are:

- `mjs` for ECMAScript modules,
- `cjs` for CommonJS modules,
- `json` for JSON modules,
- `text` for UTF-8 encoded text files,
- `bytes` for any file, exporting a `Uint8Array` as `default`,
- `pre-mjs-json` for pre-compiled ECMAScript modules captured as JSON in
  archives, and
- `pre-cjs-json` for pre-compiled CommonJS modules captured as JSON in
  archives.

The compartment mapper accepts extensions to this set of languages with
the `parserForLanguage` option supported by many functions.
See `src/types/external.ts` for the type and expected behavior for
parsers.

These language identifiers are keys for the `moduleTransforms` and
`syncModuleTransforms` options, which may map each language to a transform
function.
The language identifiers are also the values for a `languageForExtension`,
`moduleLanguageForExtension`, and `commonjsLanguageForExtension` options to
configure additional extension-to-language mappings for a module and its
transitive dependencies.

For any package that has `type` set to `"module"` in its `package.json`,
`moduleLangaugeForExtension` will precede `languageForExtension`.
Packages with `type` set to `"commonjs"` or simply not set,
`commonjsLanguageForExtension` will precede `languageForExtension`.
This provides an hook for mapping TypeScript's `.ts` to either `.cts` or
`.mts`.

The analogous `workspaceLanguageForExtension`,
`workspaceCommonjsLanguageForExtension`, and
`workspaceModuleLanguageForExtension` options apply more specifically for
packages that are not under a `node_modules` directory, indicating that they
are in the set of linked workspaces and have not been built or published to
npm.

In the scope any given package, the `parsers` property in `package.json` may
override the extension-to-language mapping.

```json
{
  "parsers": { "png": "bytes" }
}
```

> TODO
>
> The compartment mapper may elect to respect some properties specified for
> import maps.

> TODO
>
> A future version of the compartment mapper may add support for
> source-to-source translation in the scope of a package or compartment.
> This would be expressed in `package.json` using a property like
> `translate` that would contain a map from file extension
> to a module that exports a suitable translator.
>
> For browser applications, the compartment mapper would use the translator
> modules in two modes.
> During development, the compartment mapper would be able to load the
> translator in the client, with the `browser` condition.
> The compartment mapper would also be able to run the translator in a separate
> non-browser compartment during bundling, so the translator can be excluded
> from the production application and archived applications.

> TODO
>
> The compartment mapper may also add support for compartment map plugins that
> would recognize packages in `devDependencies` that need to introduce globals.
> For example, _packages_ that use JSX and a virtual DOM would be able to add a
> module-to-module translator and endow the compartment with the `h` the
> translated modules need.

# Source Maps

The `makeArchive`, `makeAndHashArchive`, and `writeArchive` tools can receive a
`sourceMapHook` as one of its options.
The `sourceMapHook` receives a source map `string` for every module it
archives, along with details `compartment`, `module`, `location`, and `sha512`.
The `compartment` is the fully-qualified file URL of the package root.
The `module` is the package-relative module specifier.
The `location` is the fully-qualified file URL of the module file.
The `sha512`, if present, was generated with the `computeSha512` power from the
generated module bytes.

The functions `importArchive`, `loadArchive`, and `parseArchive`
tools can receive a `computeSourceMapLocation` option that recives the same
details as above and must return a URL.
These will be appended to each module from the archive, for debugging purposes.

The `@endo/bundle-source` and `@endo/import-bundle` tools integrate source maps
for an end-to-end debugging experience.

# XS (experimental)

The Compartment Mapper can use native XS `Compartment` and `ModuleSource` under
certain conditions:

1. The application must be an XS script that was compiled with the `xs`
  package condition.
  This causes `ses`, `@endo/module-source`, and `@endo/import-bundle` to
  provide slightly different implementations that can fall through to native
  behavior.
2. The application must opt-in with the `__native__: true` option on any
  of the compartment mapper methods that import modules like `importLocation`
  and `importArchive`.

# Design

Each of the workflows the compartment mapper executes a portion of one sequence
of underlying internals.

* search (`search.js`): Scan the parent directories of a given `moduleLocation`
  until successfully finding and reading a `package.json` for the containing
  application.
* map compartments from Node.js packages (`node-modules.js`): Find and gather
  all the `package.json` files for the application's transitive dependencies.
  Use these to construct a compartment map describing how to construct a
  `Compartment` for each application package and how to link the modules each
  exports in the compartments that import them.
* load compartments (`archive.js`): Using `compartment.load`, or
  implicitly through `compartment.import`, create a module graph for the
  application's entire working set.
  When creating an archive, this does not execute any of the modules.
  The compartment mapper uses the compartments and a special `importHook` that
  records the text of every module the main module needed.
* import modules (`import.js`, `import-archive.js`): Actually execute the
  working set.

Around this sequence, we can enter late or depart early to store or retrieve an
archive.
The compartment mapper provides workflows that use `read` and `write` hooks
when interacting with a filesystem or work with the archive bytes directly.

This diagram represents the the workflows of each of the public methods like
`importLocation`.
Each column of pipes `|` is a workflow from top to bottom.
Each asterisk `*` denotes a step that is taken by that workflow.
The dotted lines `.'. : '.'` indicate carrying an archive file from the end of
one workflow to the beginning of another, either as bytes or a location.

In the diagram, "powers" refer to globals and built-in modules that may provide
capabilities to a compartment graph.
For `writeArchive` and `makeArchive`, these may be provided but will be ignored
since the application does not execute.

```
                 loadLocation  writeArchive
             importLocation |  | makeArchive
                          | |  | |
                          | |  | |      parseArchive
                          | |  | |      | loadArchive
                          | |  | |      | | importArchive
                          | |  | |      | | |...
               search ->  * *  * *      | |'| . '
     map compartments ->  * *  * *   .'.| | |' : :
         read archive ->  |    | |  '   | * *  : :
       unpack archive ->  |    | |  :   * * *  : :
assemble compartments ->  *    * *  :       *  : : <- powers
    load compartments ->  *    * *  :       *  : :
       import modules ->  *    | |  :       *  : :
         pack archive ->       * *  '          : :
        write archive ->       * '.' <- data   : :
                               '..............'  : <- files
                                '...............'
```

# Compartment maps

The compartment mapper works by generating a _compartment map_ from your
application workspace and all of the `node_modules` it needs.
A compartment map is similar to a lock file because it collects information
from all of the installed modules.
A compartment map describes how to construct compartments for each
package in your application and link their module namespaces.

The compartment map shape:

```ts
// CompartmentMap describes how to prepare compartments
// to run an application.
type CompartmentMap = {
  tags: Conditions,
  entry: Entry,
  compartments: Record<CompartmentName, Compartment>,
  realms: Record<RealmName, Realm>, // TODO
};

// Conditions influence which modules are selected
// to represent the implementation of various modules.
// These may include terms like "browser", meaning
// each compartment uses the implementation of each
// module suitable for use in a browser environment.
type Conditions = Array<Condition>;
type Condition = string;

// Entry is a reference to the module that is the module to initially import.
type Entry = CompartmentModule;

// CompartmentName is an arbitrary string to name
// a compartment for purposes of inter-compartment linkage.
type CompartmentName = string;

// Compartment describes where to find the modules
// for a compartment and how to link the compartment
// to modules in other compartments, or to built-in modules.
type Compartment = {
  location: Location,
  modules: ModuleMap,
  parsers: ParserMap,
  types: ModuleParserMap,
  scopes: ScopeMap,
  // The name of the realm to run the compartment within.
  // The default is a single frozen realm that has no name.
  realm: RealmName? // TODO
};

// Location is the URL relative to the compartment-map.json's
// containing location to the compartment's files.
type Location = string;

// ModuleMap describes modules available in the compartment
// that do not correspond to source files in the same compartment.
type ModuleMap = Record<InternalModuleSpecifier, Module>;

// Module describes a module in a compartment.
type Module = CompartmentModule | FileModule | ExitModule;

// CompartmentModule describes a module that isn't in the same
// compartment and how to introduce it to the compartment's
// module namespace.
type CompartmentModule = {
  // The name of the foreign compartment:
  // TODO an absent compartment name may imply either
  // that the module is an internal alias of the
  // same compartment, or given by the user.
  compartment: CompartmentName?,
  // The name of the module in the foreign compartment's
  // module namespace:
  module: ExternalModuleSpecifier?,
};

// FileLocation is a URL for a module's file relative to the location of the
// containing compartment.
type FileLocation = string

// FileModule is a module from a file.
// When loading modules off a file system (src/import.js), the assembler
// does not need any explicit FileModules, and instead relies on the
// compartment to declare a ParserMap and optionally ModuleParserMap and
// ScopeMap.
// The compartment mapper provides a Compartment importHook and moduleMapHook
// that will search the filesystem for candidate module files and infer the
// type from the extension when necessary.
type FileModule = {
   location: FileLocation,
   parser: Parser,
};

// ExitName is the name of a built-in module, to be threaded in from the
// modules passed to the module executor.
type ExitName = string;

// ExitModule refers to a module that comes from outside the compartment map.
type ExitModule = {
  exit: ExitName
};

// InternalModuleSpecifier is the module specifier
// in the namespace of the native compartment.
type InternalModuleSpecifier = string;

// ExternalModuleSpecifier is the module specifier
// in the namespace of the foreign compartment.
type ExternalModuleSpecifier = string;

// ParserMap indicates which parser to use to construct module sources
// from sources, for each supported file extension.
// For parity with Node.js, a package with `"type": "module"` in its
// `package.json` would have a parser map of `{"js": "mjs", "cjs": "cjs",
// "mjs": "mjs"}`.
// If `"module"` is not defined in package.json, the legacy parser map // is
// `{"js": "cjs", "cjs": "cjs", "mjs": "mjs"}`.
// The compartment mapper adds `{"json": "json"}` for good measure in both
// cases, although Node.js (as of version 0.14.5) does not support importing
// JSON modules from ESM.
type ParserMap = Record<Extension, Parser>;

// Extension is a file extension such as "js" for "main.js" or "" for "README".
type Extension = string;

// Parser is a union of built-in parsers for module sources.
// "mjs" corresponds to ECMAScript modules.
// "cjs" corresponds to CommonJS modules.
// "json" corresponds to JSON.
type Parser = "mjs" | "cjs" | "json";

// ModuleParserMap is a table of internal module specifiers
// to the parser that should be used, regardless of that module's
// extension.
// Node.js allows the "module" property in package.json to denote
// a file that is an ECMAScript module, regardless of its extension.
// This is the mechanism that allows the compartment mapper to respect that
// behavior.
type ModuleParserMap = Record<InternalModuleSpecifier, Parser>;

// ScopeMap is a map from internal module specifier prefixes
// like "dependency" or "@organization/dependency" to another
// compartment.
// The compartment mapper uses this to build a moduleMapHook that can dynamically
// generate entries for a compartment's moduleMap into Node.js packages that do
// not explicitly state their "exports".
// For these modules, any specifier under that prefix corresponds
// to a link into some internal module of the foreign compartment.
>> When the compartment mapper creates an archive, it captures all of the Modules
>> explicitly and erases the scopes entry.
type ScopeMap = Record<InternalModuleSpecifier, Scope>;

// Scope describes the compartment to use for all ad-hoc
// entries in the compartment's module map.
type Scope = {
  compartment: CompartmentName
};


// TODO everything hereafter...

// Realm describes another realm to contain one or more
// compartments.
// The default realm is frozen by lockdown with no
// powerful references.
type Realm = {
  // TODO lockdown options
};

// RealmName is an arbitrary identifier for realms
// for reference from any Compartment description.
// No names are reserved; the default realm has no name.
type RealmName = string;

// ModuleParameter indicates that the module does not come from
// another compartment but must be passed expressly into the
// application by the user.
// For example, the Node.js `fs` built-in module provides
// powers that must be expressly granted to an application
// and may be attenuated or limited by the compartment mapper on behalf of the
// user.
// The string value is the name of the module to be provided
// in the application's given module map.
type ModuleParameter = string;
```

# Compartment map policy

The `policy` option accepted by the compartment-mapper API methods provides means to narrow down the endowments passed to each compartment independently.  
The rules defined by policy get preserved in the compartment map and enforced in the application. To explore how policies work, see [Policy Demo].

The shape of the `policy` object is based on `policy.json` from LavaMoat. MetaMask's [LavaMoat] generates a `policy.json` file that serves the same purposes, using a tool called TOFU: _trust on first use_.

> TODO
>
> Endo policy support is intended to reach parity with LavaMoat's policy.json.
> Policy generation may be ported to Endo.


  [LavaMoat]: https://github.com/LavaMoat/lavamoat
  [Compartments]: ../ses/README.md#compartment
  [Policy Demo]: ./demo/policy/README.md
  [package entry points]: https://nodejs.org/api/esm.html#esm_package_entry_points

-----END FILE compartment-mapper/README.md-----
-----BEGIN FILE daemon/README.md-----
# Endo Daemon

This package provides the Endo daemon and controller.
The controller manages the Endo daemon lifecycle.

The Endo daemon is a persistent host for managing guest programs in hardened
JavaScript worker processes.
The daemon communicates through a Unix domain socket or named pipe associated
with the user, and manages per-user storage and compute access.

Over that channel, the daemon communicates in CapTP over netstring message
envelopes.
The bootstrap provides the user agent API from which one can derive facets for
other agents.

-----END FILE daemon/README.md-----
-----BEGIN FILE env-options/README.md-----
# Parameterizing Modules with Environment Options

JavaScript module semantics resist attempts to parameterize a module's
initialization behavior. A module initializes in order according to
the path by which it is first imported, and then the initialized module
is reused by all the other times it is imported. Compartments give us
the opportunity to bind the same import name to different imported
modules, depending on the package/compartment doing the import. Compartments
also address the difficulty of parameterizing a module's initialization
logic, but not in a pleasant manner.

A pleasant parameterization would be for a static module to be function-like
with explicit parameters, and for the parameterization to be like
calling the static module with parameters in order to derive from it a
module instance. Compartments instead lets us parameterize the meaning
of a module instance derived from a static module according to the
three namespaces provided by the JavaScript semantics, affecting the
meaning of a module instance.
   * The global variable namespaces.
      * The global scope, aliased to properties of the global object.
        This is necessarily compartment-wide. In our
        recommened usage pattern of one compartment per package,
        each global would be package-wide. (See LavaMoat)
      * The global lexical scope. The SES-shim compartments support
        these both compartment-wide as well as per-module. But it is
        not yet clear what we will propose in the Compartment proposal.
   * The import namespace.
   * The host hooks.

This `@endo/env-options` package follows the Node precedent for
finding Unix environment variable settings: looking for a
global `process` object holding an `env` object,
optionally holding a property with the same name as the option,
whose value is the configuration setting of that option.

```js
import { getEnvironmentOption } from '@endo/env-options';
const FooBarOption = getEnvironmentOption('FOO_BAR', 'absent');
```

The first argument to `getEnvironmentOption` is the name of the option.
The value of `FooBarOption` would then be the value of
`globalThis.process.env.FOO_BAR`, if present.
If value is either absent or `undefined`, the second argument,
such as `'absent'`, would be used instead.

In either case, reflecting Unix environment variable expectations,
the resulting setting must be a string.
This restriction also helps ensure that this channel is used only to pass data,
not authority beyond the ability to read this global state.

```js
const ENABLED =
  getEnvironmentOption('TRACK_TURNS', 'disabled', ['enabled']) === 'enabled';
```

`getEnvironmentOption` also takes an optional third argument, which if present
is an exhaustive list of allowed strings other than the default. If present
and the actual environment option is neither the default nor one of these
allowed strings, then an error is thrown explaining the problem.

```js
const DEBUG_VALUES = getEnvironmentOptionsList('DEBUG');
const DEBUG_AGORIC = environmentOptionsListHas('DEBUG', 'agoric');
```

Another common convention is for the value of an option to be a
comma (`','`) separated list of strings. `getEnvironmentOptionsList` will
return this list, or an empty list if the option is absent.
`environmentOptionsListHas` will test if this list contains a specific
value, or return false if the option is absent.

(Compat note: https://github.com/Agoric/agoric-sdk/issues/8096 explains that
for `DEBUG` specifically, some existing uses split on colon (`':'`) rather
than comma. Once these are fixed, then these uses can be switched to use
`getEnvironmentOptionsList` or `environmentOptionsListHas`.)

## Tracking used option names

The `'@endo/env-options'` module also exports a lower-level
`makeEnvironmentCaptor` that you can apply to whatever object you wish to treat
as a global(having a "process" property with its own "env" record),
such as the global of another compartment. It returns an entagled
pair of a `getEnvironmentOption` function as above, and a
`getCapturedEnvironmentOptionNames` function that returns an array of
the option names used by that `getEnvironmentOption` function. This is
useful to give feedback about
which environment variables were actually read, for diagnostic purposes.
For example, the
ses-shim `lockdown` once contained code such as the following, to explain which
environment variables were read to provide `lockdown` settings.

```js
import { makeEnvironmentCaptor } from '@endo/env-options';
const {
  getEnvironmentOption,
  getEnvironmentOptionsList,
  environmentOptionsListHas,
  getCapturedEnvironmentOptionNames,
} = makeEnvironmentCaptor(globalThis);
...
const capturedEnvironmentOptionNames = getCapturedEnvironmentOptionNames();
if (capturedEnvironmentOptionNames.length > 0) {
  console.warn(
    `SES Lockdown using options from environment variables ${enJoin(
      arrayMap(capturedEnvironmentOptionNames, q),
      'and',
    )}`,
  );
}
```

# Note of test migration

To reduce cyclic dependencies, the tests of this module have been moved to
@endo/ses-ava. Doing `yarn test` here currently does nothing.

-----END FILE env-options/README.md-----
-----BEGIN FILE errors/README.md-----


-----END FILE errors/README.md-----
-----BEGIN FILE eslint-plugin/README.md-----
# @endo/eslint-plugin

Endo-specific plugin

## Installation

You'll first need to install [ESLint](http://eslint.org):

```sh
npm i eslint --save-dev
```

Next, install `@endo/eslint-plugin`:

```sh
npm install @endo/eslint-plugin --save-dev
```

**Note:** If you installed ESLint globally (using the `-g` flag) then you must also install `@endo/eslint-plugin` globally.

## Usage

Extend a `plugin:@endo/CONFIG` in your `.eslintrc` configuration file. You can omit the `/eslint-plugin` suffix:

```json
{
    "extends": [
        "plugin:@endo/recommended"
    ]
}
```

`CONFIG` can be one of:

- `recommended` rules for code compatible with Hardened JS
- `imports` opinions on how packages should use imports
- `style` opinions on JS coding style
- `strict` all of the above
- `internal` rules only for packages within the Endo source repository


You can configure individual rules you want to use under the rules section.

```json
{
    "rules": {
        "@endo/rule-name": 2
    }
}
```

## Supported Rules

* Fill in provided rules here

-----END FILE eslint-plugin/README.md-----
-----BEGIN FILE evasive-transform/README.md-----
# @endo/evasive-transform

> Source transforms for evading censorship in [SES](https://github.com/endojs/endo/tree/master/packages/ses)-enabled applications

This package provides a function which transforms comments contained in source code which would otherwise be rejected outright by SES.

## Example

```js
// ESM example
import { evadeCensor } from '@endo/evasive-transform';
import fs from 'node:fs/promises';

/**
 * Imagine this file contains a comment like `@property {import('foo').Bar} bar`. SES will refuse to run this code.
 */
const source = await fs.readFile('./dist/index.js', 'utf8');
const sourceMap = await fs.readFile('./dist/index.js.map', 'utf8');
const sourceUrl = 'index.js'; // assuming the source map references index.js
const sourceType = 'script';

const { code, map } = await evadeCensor(source, {
  sourceMap,
  sourceUrl,
  sourceType,
});

/**
 * The resulting file will now contain `@property {ІᛖРΟᏒТ('foo').Bar} bar`, which SES will allow (and TypeScript no longer understands, but that should be fine for the use-case). 
 * 
 * Note that this could be avoided entirely by stripping comments during, say, a bundling phase.
 */
await fs.writeFile('./dist/index.ses.js', code);
await fs.writeFile('./dist/index.ses.js.map', JSON.stringify(map));
```

## License

Apache-2.0

-----END FILE evasive-transform/README.md-----
-----BEGIN FILE eventual-send/README.md-----
# HandledPromise

[![dependency status][deps-svg]][deps-url]
[![dev dependency status][dev-deps-svg]][dev-deps-url]
[![License][license-image]][license-url]

Create a HandledPromise class to implement the eventual-send API.  This API is used by the [ECMAScript eventual-send proposal](https://github.com/tc39/proposal-eventual-send).

## How to use

To install the `HandledPromise` global property shim, do:

```js
import '@agoric/eventual-send/shim';
```

After that, you can use `HandledPromise` in any of your code.  If you need access to the `E` proxy maker, do:

```js
import { E } from '@agoric/eventual-send';
```

[deps-svg]: https://david-dm.org/Agoric/eventual-send.svg
[deps-url]: https://david-dm.org/Agoric/eventual-send
[dev-deps-svg]: https://david-dm.org/Agoric/eventual-send/dev-status.svg
[dev-deps-url]: https://david-dm.org/Agoric/eventual-send?type=dev
[license-image]: https://img.shields.io/badge/License-Apache%202.0-blue.svg
[license-url]: LICENSE

-----END FILE eventual-send/README.md-----
-----BEGIN FILE exo/README.md-----
# `@endo/exo`

An Exo object is an exposed Remotable object with methods (aka a Far object) which is normally defined with an InterfaceGuard as a protective outer layer, providing the first layer of defensiveness.

This `@endo/exo` package defines the APIs for making Exo objects, and for defining ExoClasses and ExoClassKits for making Exo objects.

See [exo-taxonomy](./docs/exo-taxonomy.md) for the taxonomy and naming conventions for the elements of this API.

When an exo is defined with an InterfaceGuard, the exo is augmented by default with a meta-method for obtaining the self-describing InterfaceGuard from the exo:

```js
// `GET_INTERFACE_GUARD` holds the name of the meta-method
import { GET_INTERFACE_GUARD } from '@endo/exo';
import { getInterfaceMethodKeys } from '@endo/patterns';

...
   const interfaceGuard = await E(exo)[GET_INTERFACE_GUARD]();
   // `methodNames` omits names of automatically added meta-methods like
   // the value of `GET_INTERFACE_GUARD`.
   // Others may also be omitted if allowed by interfaceGuard options
   const methodNames = getInterfaceMethodKeys(interfaceGuard);
...
```

-----END FILE exo/README.md-----
-----BEGIN FILE far/README.md-----
# Endo Far Object helpers

The `@endo/far` package provides a convenient way to use the Endo
[distributed objects system](https://docs.agoric.com/guides/js-programming/) without  relying on the underlying messaging
implementation.

It exists to reduce the boilerplate in Hardened JavaScript vats that are running
in Agoric's SwingSet kernel,
[`@agoric/swingset-vat`](https://github.com/Agoric/agoric-sdk/tree/master/packages/SwingSet),
or arbitrary JS programs using Hardened JavaScript and communicating via
[`@endo/captp`](../captp/README.md).

You can import any of the following from `@endo/far`:

```js
import { E, Far, getInterfaceOf, passStyleOf } from '@endo/far';
```

-----END FILE far/README.md-----
-----BEGIN FILE immutable-arraybuffer/README.md-----
# `@endo/immutable-arraybuffer`

This `@endo/immutable-arraybuffer` package provides both a ponyfill and a shim for a proposed new JavaScript feature: *Immutable ArrayBuffers*.
- A ponyfill just defines and exports new things without modifying old things. The `index.js` file implements the ponyfill, providing the exports of the unqualified `@endo/immutable-arraybuffer` package.
- A shim modifies the existing JavaScript primordials as needed to most closely emulate the feature as proposed. The `shim.js` file uses the exports from `index.js` to modify `ArrayBuffer.prototype` to resemble the API being proposed. Importing `@endo/immutable-arraybuffer/shim.js` will cause these changes.

Below, we use the term "buffer" to refer informally to an instance of an `ArrayBuffer`, whether immutable or not.

## Background

Prior proposals [In-Place Resizable and Growable `ArrayBuffer`s](https://github.com/tc39/proposal-resizablearraybuffer) and [ArrayBuffer.prototype.transfer and friends](https://github.com/tc39/proposal-arraybuffer-transfer) have both reached stage 4, and so are now an official part of JavaScript. Altogether, `ArrayBuffer.prototype` now has the following methods:
- `transfer(newByteLength?: number) :ArrayBuffer` -- move the contents of the original buffer to a new buffer, detach the original buffer, and return the new buffer. The new buffer will be as resizable as the original was.
- `transferToFixedLength(newByteLength?: number) :ArrayBuffer` -- like `transfer` but the new buffer is not resizable.
- `resize(newByteLength: number) :void` -- change the size of this buffer if possible, or throw otherwise.
- `slice(start?: number, end?: number) :ArrayBuffer` -- Return a new buffer whose initial contents are a copy of that region of the original buffer. The original buffer is unmodified.

and the following read-only accessor properties
- `detached: boolean` -- is this buffer detached, or are its contents still available from this buffer object?
- `resizable: boolean` -- can this buffer be resized, or is it fixed-length?
- `byteLength: number` -- how big are the current contents of this buffer?
- `maxByteLength: number` -- how big could this buffer be resized to be?

None of the operations above enable the creation of an immutable buffer, i.e., a non-detached buffer whose contents cannot be changed, resized, or detached.

Both a `DataView` object and a `TypedArray` object are views into a buffer backing store. For a `TypedArray` object, the contents of the backing store appear as indexed data properties of the `TypeArray` object that reflect the current contents of this backing store. Currently, because there is no way to prevent the contents of the backing store from being changed, `TypedArray`s cannot be frozen.

Some JavaScript implementations, like Moddable XS, bring JavaScript to embedded systems, like device controllers, where ROM is much more plentiful and cheaper than RAM. These systems need to place voluminous fixed data into ROM, and currently do so using semantics outside the official JavaScript standard.

The [OCapN](https://ocapn.org/) network protocol treats strings and byte-arrays as distinct forms of bulk data to be transmitted by copy. At JavaScript endpoints speaking OCapN such as `@endo/pass-style` + `@endo/marshal`, JavaScript strings represent OCapN strings. The immutability of strings in the JavaScript language reflects their by-copy nature in the protocol. Likewise, to reflect an OCapN byte-array well into the JavaScript language, we need an immutable container of bulk binary data. There currently are none. An Immutable `ArrayBuffer` would provide exactly the low-level machinery we need.

## Overview of the *Immutable ArrayBuffer* Proposal

The *Immutable ArrayBuffer* proposal introduces additional methods and read-only accessor properties to `ArrayBuffer.prototype` that fit naturally into those explained above. Just as a buffer can be resizable or not, or detached or not, this proposal enables buffers to be immutable or not. Just as `transferToFixedSize` moves the contents of a original buffer into a newly created non-resizable buffer, this proposal provides a transfer operation that moves the contents of an original original buffer into a newly created immutable buffer. Altogether, this proposal only adds to `ArrayBuffer.prototype` one method
- `transferToImmutable() :ArrayBuffer` -- move the contents of the original buffer into a new immutable buffer, detach the original buffer, and return the new buffer.

and one read-only accessor
- `immutable: boolean` -- is this buffer immutable, or can its contents be changed?

An immutable buffer cannot be detached or resized. Its `maxByteLength` is the same as its `byteLength`. A `DataView` or `TypedArray` using an immutable buffer as its backing store can be frozen and immutable. `ArrayBuffer`s, `DataView`s, and `TypedArray`s that are frozen and immutable could be placed in ROM without going beyond JavaScript's official semantics.

## The Ponyfill

The proposal would add methods to `ArrayBuffer.prototype`. But a ponyfill, by definition, cannot do so. Instead, it defines and exports two functions corresponding to the two additions above
- `transferBufferToImmutable(buffer: ArrayBuffer) :ArrayBuffer`
- `isBufferImmutable(buffer: ArrayBuffer) :boolean`

In order for `transferBufferToImmutable` to be able to return something of type `ArrayBuffer` that is actually immutable, that object cannot be an actual `ArrayBuffer` exotic object. Instead, an emulated immutable buffer implements the full proposed `ArrayBuffer` API and ultimately inherits from `ArrayBuffer.prototype`. Thus, `x instanceof ArrayBuffer` will act as proposed.

The emulated immutable buffers inherit directly from an intermediate prototype we refer to as `immutableArrayBufferPrototype`. This intermediate prototype contains all the methods and read-only accessor properties proposed here, as well as overrides of those inherited from `ArrayBuffer.prototype` as needed to emulate the behavior of an immutable instance. For each emulated immutable buffer, the implementation encapsulates a genuine `ArrayBuffer` that it has exclusive access to, so it can enforce immutability simply by never modifying it.

## The Shim

The immutable-arraybuffer shim additionally adds to `ArrayBuffer.prototype` a
- `transferToImmutable` method trivially derived from the ponyfill's `transferBufferToImmutable`.
- `immutable` read-only accessor property trivially derived from the ponyfill's `isBufferImmutable`.

## Caveats

The *Immutable ArrayBuffer* shim falls short of the proposal in the following ways
- The ponyfill and shim rely on the underlying platform having either `structuredClone` or `ArrayBuffer.prototype.transfer`. However, Node <= 16 has neither. Node 17 introduces `structuredClone` and Node 21 introduces `ArrayBuffer.prototype.transfer`. Without either, the ponyfill and shim fail to initialize.
- The proposal does not introduce an intermediate prototype, but rather modifies the behavior of the built-in methods on `ArrayBuffer.prototype` itself, to act appropriately on immutable `ArrayBuffer`s. By contrast, the ponyfill's and shim's emulated immutable buffers inherit directly from an intermediate prototype we refer to as `immutableArrayBufferPrototype`. That intermediate prototype directly inherits from `ArrayBuffer.prototype`. All the differential behavior for immutable buffers are provided by overrides found on `immutableArrayBufferPrototype`.
- The `immutableArrayBufferPrototype` intermediate prototype is an artifact of the emulation, but it is not encapsulated. It is trivially discoverable as the object that emulated immutable buffers directly inherit from.
- The shim's emulated immutable buffers are not real `ArrayBuffer` exotic objects. If they were, the shim would not be able to protect them from being written. Even though they implement the full proposed `ArrayBuffer` API, they cannot be plug-compatible -- they cannot be used as the backing stores of `DataView`s or `TypedArray`s. Perhaps follow-on shims might modify `DataView` and `TypedArray` to emulate that as well, but that is hard and beyond the ambition of this ponyfill + shim.
- Unlike genuine `ArrayBuffer` or `SharedArrayBuffer` exotic objects, the shim's emulated immutable buffers cannot be cloned or transfered between JS threads.
- Even after the *Immutable ArrayBuffer* proposal is implemented by the platform, the current code will still replace it with the shim implementation, in accord with shim best practices. See https://github.com/endojs/endo/pull/2311#discussion_r1632607527 . It will require a later manual step to delete the shim, after manual analysis of the compat implications.
- This is a plain *JavaScript* ponyfill/shim, not by itself a *Hardened JavaScript* polyfill/shim. Thus, the objects and function it creates are not hardened by this ponyfill/shim itself. Rather, the ses-shim is expected to import these, and then treat the resulting objects as if they were additional primordials, to be hardened during `lockdown`'s harden phase.

-----END FILE immutable-arraybuffer/README.md-----
-----BEGIN FILE import-bundle/README.md-----
# import-bundle

`importBundle` is an async function that evaluates the bundles created by
`bundle-source`, turning them back into callable functions:

```js
const bundle = await bundleSource('path/to/bundle.js');
// 'bundle' is JSON-serializable
const options = {}; // filePrefix, endowments, other compartment options
const namespace = await importBundle(bundle);
const { default, namedExport1, namedExport2 } = namespace;
```

This must be run in a SES environment: you must install SES before importing
`@endo/import-bundle`.
The conventional way to do this is to import a module (e.g. `@endo/init`) which
does `import 'ses'; lockdown();`.

The bundle will be loaded into a new Compartment, which does not have access to
platform globals like `document` or `Fetch` or `require`.
The bundle is isolated to only having access to powerless JavaScript facilities
and whatever endowments you provide.

Each call to `importBundle` creates a new `Compartment`.
The globals of the new Compartment are frozen before any bundle code is
evaluated, to enforce ocap rules.

## Module Formats

The source can be bundled in a variety of "formats".

By default, `bundleSource` uses a format named `endoZipBase64`, in which the
source modules and a "compartment map" are captured in a Zip file and base-64
encoded.
The compartment map describes how to construct a set of [Hardened
JavaScript](https://hardenedjs.org) compartments and how to load and link the
source modules between them.

The `endoScript` format captures the sources as a single JavaScript program
that completes with the entry module's namespace object.

The `getExport` format captures the sources as a single CommonJS-style string,
and wrapped in a callable function that provides the `exports` and
`module.exports` context to which the exports can be attached.

More sophisticated than `getExport` is named `nestedEvaluate`.
In this mode, the source tree is converted into a table of evaluable strings,
one for each original module.
This table is then encoded and wrapped as before.
The evaluation process uses a separate evaluator call for each module,
providing an opportunity to attach a distinct `sourceMap` to each one.
This preserves relative filenames in subsequent debugging information and stack
traces.

To set a base prefix for these relative filenames, provide the `filePrefix`
option.

Note that the `nestedEvaluate` format receives a global endowment named
`require`, although it will only be called if the source tree imported one of
the few modules on the `bundle-source` "external" list.

## Options

`importBundle()` takes an options bag and optional additional powers.

```js
const namespace = await importBundle(bundle, options, powers);
```

The most common option is `filePrefix`, which can be provided for
`nestedEvaluate`-format bundles.
This sets the source filename of the top-level module inside the bundle, as
used in debugging messages (like the stack traces displayed in errors).
The other modules will append a suffix to this filename, based upon their
location within the original source tree.

Another common option is `endowments`, which provides names that will be
available everywhere in the evaluated sources.
By default, the bundle will only get access to the standard JavaScript
primordials (`Array`, `Object`, `Map`, etc).
It will not get `document`, `window`, `Request`, `process`, `require`, or even
`console` unless you provide them as endowments, giving you full control over
what the loaded bundle can do.

The `bundle-source` tool has a small number of module names marked as
"external".
These modules are not bundled into the source (copied from the filesystem where
`bundleSource` was called).
Instead, the bundler injects a call to `require()` for each external module
that was imported from somewhere in original source graph.
This let the final evaluation environment control what these imports get,
rather than the original source tree.

To support these "external" imports, you will need to provide a `require`
endowment that can honor any such names.
In addition, the `nestedEvaluate` format always needs a `require` endowment
(although it will only be called if the original sources imported one of the
"external" names).

For debugging purposes, you should probably provide a `console` endowment.
See `makeConsole.js` in the SwingSet source tree for inspiration.

The rest of the `options` are passed through to the `Compartment` constructor,
which currently only accepts `transforms`.
For more information, see the `compartment-shim` docs in the SES repository.
Note that `transforms` is defined to be an array of objects which each have a
`rewrite` method.

Note that `sloppyGlobalsMode` is only accepted by the Compartment's `evaluate`
method, not the Compartment constructor itself, and thus cannot be supplied to
`importBundle`.
To use `sloppyGlobalsMode`, you will probably want to create a Compartment
directly (and not freeze its globals).

## Source maps

For an Endo (zip, base64) bundle, `bundleSource` will add source maps to a
per-user cache so they can be debugged if imported on the same host.
To use this facility, pass a `computeSourceMapLocation` capability into
`powers`.

```js
import 'ses';
import bundleSource from '@endo/bundle-source';
import { importBundle } from '@endo/import-bundle';
import { computeSourceMapLocation } from '@endo/import-bundle/source-map-node.js';

lockdown();
const bundle = await bundleSource('debugme.js');
await importBundle(
  bundle,
  { endowments: { console } },
  { computeSourceMapLocation },
);
```

Use `node --inspect-brk` and `debugger` statements.

-----END FILE import-bundle/README.md-----
-----BEGIN FILE lp32/README.md-----
# LP32

Also known as the web extension "Native Host Message" protocol, this package
implements async iterator streams for reading and writing with 32-bit
host-byte-order length-prefix message envelopes for binary data, represented
with Uint8Arrays.

These streams are "hardened" and depend on Hardened JavaScript.
Most JavaScript environments can be locked down with the
[SES shim](../ses/README.md).

-----END FILE lp32/README.md-----
-----BEGIN FILE marshal/README.md-----
# @endo/marshal

"Marshalling" refers to the conversion of structured data (a tree or graph of
objects) into a string, and back again.

The `marshal` module helps with conversion of "capability-bearing data", in
which some portion of the structured input represents "pass-by-proxy" or
"pass-by-presence" objects that should be serialized into values referencing
special "slot identifiers". The `toCapData()` function returns a "CapData"
structure: an object with a `body` containing a serialization of the input data,
and a `slots` array holding the slot identifiers. `fromCapData()` takes this
CapData structure and returns the object graph. There is no generic way to
convert between pass-by-presence objects and slot identifiers, so the marshaller
is parameterized with a pair of functions to create the slot identifiers and turn
them back into proxies/presences.

`marshal` uses JSON to serialize the object graph, but knows how to serialize
values that cannot be expressed directly in JSON, such as bigints, `NaN`, and
`undefined`.

## Usage

This module exports a `makeMarshal()` function, which can be called with two
optional callbacks (`convertValToSlot` and `convertSlotToVal`), and returns
an object with `toCapData` and `fromCapData` properties. Each callback defaults
to the identity function.

```js
import '@endo/init';
import { makeMarshal } from '@endo/marshal';

const m = makeMarshal();
const o = harden({a: 1});
const s = m.toCapData(o);
console.log(s);
// { body: '{"a":1}', slots: [] }
const o2 = m.fromCapData(s);
console.log(o2);
// { a: 1 }
console.log(o1 === o2);
// false
```

Additionally, this module exports a `makePassableKit` function for encoding into
and decoding from a directly-serialized format in which string comparison
corresponds with arbitrary value comparison (cf.
[Patterns: Rank order and key order](https://github.com/endojs/endo/blob/master/packages/patterns/README.md#rank-order-and-key-order).
Rather than accepting `convertValToSlot` and `convertSlotToVal` functions and
keeping a "slots" side table, `makePassableKit` expects
{encode,decode}{Remotable,Promise,Error} functions that directly convert between
instances of the respective pass styles and properly-formatted encodings
(in which Remotable encodings start with "r", Promise encodings start with "?",
Error encodings start with "!", and all other details are left to the provided
functions).
`makePassableKit` supports two variations of this format: "legacyOrdered" and
"compactOrdered". The former is the default for historical reasons (see
https://github.com/endojs/endo/pull/1594 for background) but the latter is
preferred for its better handling of deep structure. The ordering guarantees are
upheld within each format variation, but not across them (i.e., it is not
correct to treat a string comparison of legacyOrdered vs. compactOrdered as a
corresponding value comparison).

## Frozen Objects Only

The entire object graph must be "hardened" (recursively frozen), such as done
by the `harden` function installed when importing `@endo/init`. `toCapData` will
refuse to marshal any object graph that contains a non-frozen object.

## Beyond JSON

`marshal` uses special values to represent both Presences and data which cannot
be expressed directly in JSON. These special values are usually strings with
reserved prefixes in the preferred "smallcaps" encoding, but in the original
encoding were objects with a property named `@qclass`. For example:

```js
import '@endo/init';
import { makeMarshal } from '@endo/marshal';

// Smallcaps encoding.
const m1 = makeMarshal(undefined, undefined, { serializeBodyFormat: 'smallcaps' });
console.log(m1.toCapData(NaN));
// { body: '#"#NaN"', slots: [] }

// Original encoding.
const m2 = makeMarshal();
console.log(m2.toCapData(NaN));
// { body: '{"@qclass":"NaN"}', slots: [] }
```

## Pass-by-Presence vs Pass-by-Copy

`marshal` relies upon `@endo/pass-style` to distinguish between objects that are
pass-by-presence and those that are pass-by-copy.

To qualify as pass-by-presence, all properties of an object (and of all objects
in its inheritance hierarchy) must be methods, not data. Pass-by-presence objects
are usually treated as having identity (assuming the `convertValToSlot` and
`convertSlotToVal` callbacks behave well), so passing the same object through
multiple calls will result in multiple references to the same output object.

To qualify as pass-by-copy, all properties of an object must be string-named and
enumerable and not accessors and not methods: their values can be primitives such
as bigints, booleans, `null`, numbers, and strings, and they can be arrays and
pass-by-copy objects, but they cannot be functions. In addition, the object must
inherit directly from `Object.prototype`. Pass-by-copy objects are not treated as
having identity: `fromCapData` does not produce the same output object for
multiple appearances of the same pass-by-copy serialization.

Mixed objects having both methods and data properties are rejected.

Empty objects (which vacuously satisfy requirements for both pass-by-presence and
pass-by-copy) are treated as pass-by-copy, although it is also possible to use
`Far` (from `@endo/far`) for creating empty marker objects which _can_ be
compared for identity and are especially useful as WeakMap keys in the "rights
amplification" pattern.

## `convertValToSlot` / `convertSlotToVal`

When `m.toCapData()` encounters a pass-by-presence object, it will call the
`convertValToSlot` callback with the value to be serialized. The return value
will be used as the slot identifier to be placed into the slots array, and the
serialized `body`, in place of the object, will contain a special value
referencing that slot identifier by its index in the slots array. For example:

```js
import '@endo/init';
import { makeMarshal } from '@endo/marshal';

const slotAssignments = new Map();
const convertValToSlot = obj => {
  let slot = slotAssignments.get(obj);
  if (slot === undefined) {
    slot = `id1:${(slotAssignments.size + 10).toString(36)}`;
    slotAssignments.set(obj, slot);
  }
  return slot;
};

const p = harden(Promise.resolve());

// Smallcaps encoding.
const m1 = makeMarshal(convertValToSlot, undefined, { serializeBodyFormat: 'smallcaps' });
m1.toCapData(p);
// { body: '#"&0"', slots: [ 'id1:a' ] }

// Original encoding.
const m2 = makeMarshal(convertValToSlot);
m2.toCapData(p);
// { body: '{"@qclass":"slot","index":0}', slots: [ 'id1:a' ] }
```

Each time `m.fromCapData()` encounters a slot reference, it calls
`convertSlotToVal` with the value from the slots array. `convertSlotToVal`
should create and return a proxy (or other representative) of the
pass-by-presence object.

# As a direct alternative to JSON

This marshal package also exports `stringify` and `parse` functions that are
built on the marshal encoding of passable data. They can serve as direct
substitutes for `JSON.stringify` and `JSON.parse`, respectively, with the
following differences:

* Compared to JSON, marshal's `stringify` is both more tolerant and less tolerant
  of what data it accepts. It is more tolerant in that it will encode `NaN`,
  `Infinity`, `-Infinity`, bigints, and `undefined`. It is less tolerant in that
  it accepts only pass-by-copy data according to the semantics of our distributed
  object model, as enforced by marshal---the `Passable` type exported by the
  marshal package. For example, all objects-as-records must be frozen, inherit
  from `Object.prototype`, and have only enumerable string-named data properties.
  `JSON.stringify` handles unserializable data by skipping it, but marshal's
  `stringify` rejects it by throwing an error.
* The JSON functions have parameters for customizing serialization and
  deserialization, for example with a *replacer* or *reviver*. The marshal-based
  alternatives do not.

The full marshal package will serialize `Passable` objects containing
presences and promises, because it serializes to a `CapData` structure
containing both a `body` string and a `slots` array. Marshal's `stringify`
function serializes only to a string, and so will not
accept any remotables or promises. If any are found in the input, this
`stringify` will throw an error.

Any encoding into JSON of data that cannot be represented directly, such as
`NaN`, relies on some kind of escape for the decoding side to detect and use.
For `stringify` and `parse`, this is signaled by an object with a property named
`@qclass` per the original encoding described [above](#beyond-json).

-----END FILE marshal/README.md-----
-----BEGIN FILE memoize/README.md-----


-----END FILE memoize/README.md-----
-----BEGIN FILE module-source/README.md-----
# ModuleSource

This package provides a ponyfill for the `ModuleSource` constructor, suitable
for use in the SES shim's module descriptors.
The module source accepts a JavaScript module and converts it into
a form that SES can use to emulate and confine JavaScript modules (ESMs, the
`mjs` file format) with compartments.

```js
import 'ses';
import { ModuleSource } from '@endo/module-source';

const c1 = new Compartment({}, {}, {
  name: "first compartment",
  resolveHook: (moduleSpecifier, moduleReferrer) => {
    return resolve(moduleSpecifier, moduleReferrer);
  },
  importHook: async moduleSpecifier => {
    const moduleLocation = locate(moduleSpecifier);
    const moduleText = await retrieve(moduleLocation);
    return new ModuleSource(moduleText, moduleLocation);
  },
});
```

## Source maps

The `ModuleSource` is a shim for what we hope to eventually call a native
`ModuleSource` constructor.
However, in the absence of a native `ModuleSource`, this produces a
serializable object that emulates the behavior of `ModuleSource` in conjunction
with the `Compartment` constructor from `ses`.
A detail that leaks from the implementation is that the constructor rewrites
the source, from an ESM `[[Module]]` grammar construction to a `[[Program]]`
construction suitable for confining with the compartment's confined evaluator.

This transform attempts to be unobtrusive, but currently causes some alignment
changes due to (hopefully temporary) limitations to the underlying code
generator.
In the interim, generating a source map can help.

The `ModuleSource` constructor accepts non-standards-track
`sourceMapHook` and `sourceMapUrl` options.

Previously, the sole option was a `string` argument for the `sourceUrl`, such
that this would be appended to the generated source.
This change allows for the old or new usage:

```js
new ModuleSource(source, sourceUrl);
// or
new ModuleSource(source, { sourceUrl, sourceMapUrl, sourceMapHook });
```

The `sourceMapUrl` is necessary for generating a source map.
The URL will appear only in the generated source map, so a fully qualified
source map URL is safe and allows for continuity if the map is generated and
debugged on the same host.
This is important because Endo captures precompiled Static Module Records in
bundles, excluding source maps, such that a relative path is not useful.

The `sourceMapHook` will receive a string source map and a details bag
including:

- `source`
- `sourceUrl`
- `sourceMapUrl`

Such that the receiver can store the source map somewhere as a side-effect.

Note: the `sourceMapHook` is synchronous and returns `void`.
Exceptions thrown by the hook will propagate up through the constructor.  If
the hook returns a promise, it will be dropped and rejections will go uncaught.
If the hook must do async work, these should be queued up as a job that the
caller can later await.

## XS Specific Variant

With the `xs` condition, `@endo/module-source` will not entrain Babel and will
just adapt the native `ModuleSource` to the older interface presented by this
package.
That is, the XS native `bindings` will be translated to `imports`, `exports`,
and `reexports` getters.
This form of `ModuleSource` ignores all options.

## Bug Disclosure

Please help us practice coordinated security bug disclosure, by using the
instructions in
[SECURITY.md](https://github.com/endojs/endo/blob/master/packages/ses/SECURITY.md)
to report security-sensitive bugs privately.

For non-security bugs, please use the [regular Issues
page](https://github.com/endojs/endo/issues).

-----END FILE module-source/README.md-----
-----BEGIN FILE nat/README.md-----
# Nat
[![Build Status][circleci-svg]][circleci-url]
[![dependency status][deps-svg]][deps-url]
[![dev dependency status][dev-deps-svg]][dev-deps-url]
[![License][license-image]][license-url]

Numbers in a programming language are meaningful because we take them to
represent abstract mathematical numbers. JavaScript has two data types
representing numbers, *JS numbers* (IEEE 64 bit floating point) and *bigints*
(arbitrary precision integers). Not all abstact mathematical
numbers are representable by these data types, and not all values of one of
these data types represent mathematical numbers (The JS number type's `NaN`,
`Infinity`, and `-Infinity`). Because JavaScript uses "number" to refer to
its floating point data type, we'll always say "mathematical number" when
that's what we mean.

This package is concerned with the mathematical *natural numbers*, the non-negative
integers. All of these can be safely represented as bigints, given enough
memory. Some of these can be represented as JS numbers, and a smaller set can
*safely* be represented as JS numbers, given a specific notion of safety.

A skippable detail about floating point:
  * The JavaScript expression `2**70` evaluates to a JS number that exactly
  represents the mathematical number you expect. However, the JavaScript
  expression `2**70+1 === 2**70` evaluates to `true` because this JS number is
  outside the contiguous range of integers that the JS number type can
  represent *unambiguously*.
  The contiguous range of exactly representable integers is
  `-(2**53)` to `2**53`. However, `2**53+1 === 2**53` is `true`, demonstrating
  that other integers will round to `2**53`. The JavaScript standard defines
  the [*safe* JS numbers](https://tc39.es/ecma262/#sec-number.issafeinteger)
  to be the JS numbers that represent mathematical integers and lie in the
  range `-(2**53-1)` to `2**53-1` . The JS safe natural numbers are the
  non-negative subset of that, between `0` and `2**53-1`. No other integers
  coerce to any of these. If in JavaScript `a + b === c` and all three values
  are JS safe integers, then this accurately represents the mathematical sum
  of the mathematical numbers they represent.

The bigint datatype, by contrast, is inherently safe. Every bigint `>= 0n`
safely represents a natural number.

This package exports two functions, `isNat(allegedNum)` and `Nat(allegedNum)`.

## isNat(allegedNum: any) => boolean

```js
isNat(3); // true
isNat(3n); // true
isNat('3'); // false
isNat(2**70); // false
isNat(2n**70n); // true
isNat(-3n); // false
isNat(3.1); // false
```

The `isNat` function is a predicate that accepts any input and returns `true`
iff that input safely represents a natural number, i.e., if it is a non-negative
bigint or it is a non-negative JS number safely representing an integer. To the
extent that we consider this abstract notion of mathematical natural number a
type, `isNat` is a *type tester* of possible representations of this type.

## Nat(allegedNum: bigint | number) => bigint

```js
Nat(3); // 3n
Nat(3n); // 3n
Nat('3'); // throws TypeError
Nat(2 ** 70); // throws RangeError
Nat(2n ** 70n); // 1180591620717411303424n
Nat(-3); // throws RangeError
Nat(3.1); // throws RangeError
```

The `Nat` function accepts exactly those values that pass the `isNat`
predicate. For those it returns a bigint that represents the same natural
number. Otherwise it throws.

## Validators and Coercers

Functions like `Nat` and the standard JavaScript `BigInt` can be
classified _validators_ or _coercers_.

When a validator accepts---returns normally rather than throwing---the caller
knows that their input argument is as expected, and the output is the same as
the input. When a coercer accepts, the caller knows that the output is as
expected, but only knows that the input was one the coercer was willing to
convert from. The `BigInt` function is a coercer. It will even accept
strings as input but its output is always a bigint. `Nat` is an interesting
mixture. It is a coercer at one level of abstraction, and a validator at
another level of abstraction.

At the level of concrete JavaScript data representations, `Nat` is clearly a
coercer---`Nat` will convert a qualifying JS number into a bigint. At the level
of abstraction of the mathematical number any accepted input represents, `Nat`
is a validator. If `Nat` succeeds the caller knows that their input safely
represents some abstract mathematical natural number, and that the output
safely represents the same abstract mathematical natural number. At this level
of abstraction, on success, the output is the same as the input.

## History

`Nat` comes from the Google Caja project, which tested whether a JS number was a
primitive integer within the range of continguously and unambiguously
representable non-negative integers.

For more, see the [discussion in TC39 notes](https://github.com/rwaldron/tc39-notes/blob/master/es6/2013-07/july-25.md#59-semantics-and-bounds-of-numberisinteger-and-numbermax_integer)


[circleci-svg]: https://circleci.com/gh/Agoric/nat.svg?style=svg
[circleci-url]: https://circleci.com/gh/Agoric/nat
[deps-svg]: https://david-dm.org/Agoric/Nat.svg
[deps-url]: https://david-dm.org/Agoric/Nat
[dev-deps-svg]: https://david-dm.org/Agoric/Nat/dev-status.svg
[dev-deps-url]: https://david-dm.org/Agoric/Nat?type=dev
[license-image]: https://img.shields.io/badge/License-Apache%202.0-blue.svg
[license-url]: LICENSE

-----END FILE nat/README.md-----
-----BEGIN FILE netstring/README.md-----
# netstring

This is an implementation of asynchronous streams framed as [Netstrings][].
A netstring is a binary protocol for length-prefixed frames,
using decimal strings as variable width integers.
For example, the frame `5:hello,` corresponds to the message `hello`,
where `5` is the length of `hello` in bytes.

This implementation relies particularly on the pure JavaScript notion of a
stream, using async iterators of Uint8Arrays.
By convention, these may be ranges of a ring buffer, so a stream owns a byte
range it receives from `next` until the next time it calls `next`.


[Netstrings][] <br>
D. J. Bernstein, <djb@pobox.com> <br>
1997-02-01

[Netstrings]: https://cr.yp.to/proto/netstrings.txt

-----END FILE netstring/README.md-----
-----BEGIN FILE pass-style/README.md-----
# `@endo/pass-style`

Defines the `Passable` objects, and the `passStyleOf` function for classifying them according to their `PassStyle`.

See [types.js](./src/types.js) for the actual type definitions. See also [CopyRecord guarantees](./doc/copyRecord-guarantees.md) and [CopyArray guarantees](./doc/copyArray-guarantees.md).

The Passable objects are those that can be passed by the `@endo/marshal` package. Thus `Passable` defines the layer of abstraction on which we need broad agreement for interoperability. One type of `Passable` is the `Tagged` object, which is the extension point for defining higher level data types, which do not need such broad agreement. The main such higher layer of abstraction is provided by the `@endo/patterns` package.

-----END FILE pass-style/README.md-----
-----BEGIN FILE patterns/README.md-----
# `@endo/patterns`

The main export from the package is an `M` namespace object, for making a variety of Matchers (hence "M"). For example:

```js
import '@endo/init/debug.js';
import { M, mustMatch } from '@endo/patterns';

const specimen = harden({ foo: 3, bar: 4 });

const pattern = M.splitRecord(
  { foo: M.number() }, // required properties
  { bar: M.string(), baz: M.number() }, // optional
);

mustMatch(specimen, pattern); // throws: 'bar?: number 4 - Must be a string'
```

See {@link PatternMatchers} for more on `M.splitRecord()`, `M.number()`, and other methods.

`M` also has {@link GuardMakers} methods to make {@link InterfaceGuard}s that use Patterns to characterize dynamic behavior such as method argument/response signatures and promise awaiting. The {@link @endo/exo!} package uses `InterfaceGuard`s as the first level of defense for Exo objects against malformed input.

_For best rendering, use the [Endo reference docs](https://endojs.github.io/) site._

## Key Equality, Containers

Builds on {@link @endo/pass-style!} as described in [`kindOf` and `passStyleOf` levels of abstraction](./docs/marshal-vs-patterns-level.md) to define higher level data types as individual refinements of Passable CopyTagged records (PassStyle "tagged"):
   - {@link CopySet} -- a collection of unique distinguishable {@link Key}s
   - {@link CopyBag} -- a collection of entries associating a unique distinguishable Key with a positive integer count (see [Multiset](https://en.wikipedia.org/wiki/Multiset)).
   - {@link CopyMap} -- a collection of entries associating a unique distinguishable Key with a Passable
   - {@link Matcher} -- a predicate characterizing a subset of Passables, such as "strings" or "8-bit unsigned integer numbers" or "CopyArrays of Remotables"

In support of the above, there is also {@link compareKeys} and {@link keyEQ} exposing pass-invariant Key comparison, and two concepts with corresponding TypeScript types:
   - {@link Key} -- a Passable arbitrarily deep acyclic data structure in which each non-leaf node is a CopyArray, CopyRecord, CopySet, CopyBag, or CopyMap that is the child of at most one other internal node (forming a possibly-empty tree of containers), and each leaf is either an empty such container or a Passable primitive value or a Remotable (but the same Remotable `r` may be a child of multiple parents, e.g. `{ foo: r, bar: [r] }`). A Key is stable and stably comparable with other Keys via {@link keyEQ}. Key is the most general data type covering valid contents for CopySets and CopyBags and keys for CopyMaps (the last of which explains the "Key" name).
   - {@link Pattern} -- a Passable value that can be used to *match* some subset of Passables. Each Pattern is either a Key that matches itself (and any copy of itself --- `keyEQ` considers identity only for Remotables, where it is shared across all local Presences of the same Remotable), or a Key-like structure in which one or more leaves is a Matcher rather than a primitive or Remotable.

-----END FILE patterns/README.md-----
-----BEGIN FILE promise-kit/README.md-----
# Promise Kit

The promise-kit package provides a simple abstraction for creating and managing a promise. It exports, `makePromiseKit` which is a utility function used to create a Promise and its associated resolver and rejector functions. This is particularly useful in asynchronous programming, where you might need to create a promise and resolve or reject it at a later point in time.
Note that this serves as a "ponyfill" for `Promise.withResolvers`, making certain accommodations to ensure that the resulting promises can pipeline messages through `@endo/eventual-send`.

## Usage

Here’s an example of how `makePromiseKit` might be used in an Agoric smart contract or JavaScript program:

### Basic Example

```javascript
import { makePromiseKit } from '@endo/promise-kit';

function asyncOperation() {

  const { promise, resolve, reject } = makePromiseKit();
  setTimeout(() => {
    const success = true; // Simulating success or failure
    if (success) {
      resolve("Operation successful!");
    } else {
      reject("Operation failed!");
    }
  }, 2000); 

  return promise;
}

async function handleAsyncOperation() {
  try {
    const result = await asyncOperation();
    console.log(result); // "Operation successful!"
  } catch (error) {
    console.error(error); // "Operation failed!"
  }
}

handleAsyncOperation();
```

### Creating Multiple Promise Kits

You can create multiple promise kits for managing various asynchronous tasks.

```javascript
const kit1 = makePromiseKit();
const kit2 = makePromiseKit();

kit1.promise.then(value => console.log('Kit 1 resolved with:', value));
kit2.promise.then(value => console.log('Kit 2 resolved with:', value));

kit1.resolve('First success');
kit2.resolve('Second success');

```

## API

### `makePromiseKit()`
Creates a new promise kit.

**Returns**
- **`promise`**: The promise object.
- **`resolve`**: The resolve function for the promise.
- **`reject`**: The reject function for the promise.

## Links
[Repository](https://github.com/endojs/endo/tree/master/packages/promise-kit)

## License
This package is licensed under the Apache-2.0 License.
-----END FILE promise-kit/README.md-----
-----BEGIN FILE ses-ava/README.md-----
# `@endo/ses-ava`

*SES-Ava* wraps Ava `test` functions and initializes the SES-shim with options
suitable for debugging tests. This includes logging errors to the console with
- deep stacks of prior turns
- unredacted stack traces
- unredacted error messages

To use this module, in your Ava test files, replace

```js
import 'ses'; // or however you initialize the SES-shim
import test from 'ava';
```
with
```js
import test from '@endo/ses-ava/prepare-endo.js';
```
and add
```json
  "devDependencies": {
    // ...
    "@endo/ses-ava": "...", // for the current version of @endo/ses-ava
    // ...
  },
```
specifically to "devDependencies". @endo/ses-ava itself depends on Ava as
a regular dependency, so it you include @endo/ses-ava as a regular
dependency, bundlers might bundle your code with all of Ava.

SES-Ava rhymes with Nineveh.

## Compat note

If you were already using `@endo/ses-ava` by doing

```js
import 'ses'; // or however you initialize the SES-shim
import rawTest from 'ava';
import { wrapTest } from '@endo/ses-ava';

const test = wrapTest(rawTest);
```

that code will continue to work. But it should be upgraded to the above
pattern if possible.

-----END FILE ses-ava/README.md-----
-----BEGIN FILE ses/README.md-----
# SES

SES is a [shim][define shim] for [Hardened JavaScript][] as [proposed][SES
proposal] to ECMA TC39.
SES stands for *fearless cooperation*.
Hardened JavaScript is highly compatible with ordinary JavaScript.
Most existing JavaScript libraries can run on Hardened JavaScript.

* **Compartments** Compartments are separate execution contexts: each one has
  its own global object and global lexical scope.
* **Frozen realm** Compartments share their intrinsics to avoid identity
  discontinuity. By freezing the intrinsics, SES protects programs from each
  other. By sharing the intrinsics, programs from separate compartments
  can recognize each other's arrays, data objects, and so on.
* **Strict mode** SES enforces JavaScript strict mode that enhances security,
  for example by changing some silent failures into thrown errors.
* **POLA** (Principle of Least Authority) By default, Compartments receive no
  ambient authority. They are created without host-provided APIs, (for example
  no `fetch`). Compartments can be selectively endowed with powerful arguments,
  globals, or modules.

SES safely executes third-party JavaScript 'strict' mode programs in
compartments that have no excess authority in their global scope.
SES runs atop an ES6-compliant platform, enabling safe interaction of
mutually-suspicious code, using object-capability -style programming.

Agoric and MetaMask rely on Hardened JavaScript and this SES shim as part of
systems that sandbox third-party plugins or smart contracts and mitigate supply
chain attacks for production web applications, web extensions, and build
systems.

[![Agoric Logo](docs/agoric-x100.png)](https://agoric.com/)
[![MetaMask Logo](docs/metamask-x100.png)](https://metamask.io/)

See https://github.com/Agoric/Jessie to see how SES fits into the various
flavors of confined JavaScript execution. And visit
https://ses-demo.agoric.app/demos/ for a demo.

SES starts where the Caja project left off
https://github.com/google/caja/wiki/SES, and goes on to introduce compartments
and modernize the permitted JavaScript features.

Please join the conversation on our [Mailing List][SES Strategy Group] and
[Matrix][Endo Matrix].
We record a [weekly conference call][SES Strategy Recordings] with the Hardened
JavaScript engineering community.

_Hardened JavaScript_, Kris Kowal:

[![Primer on Hardened JavaScript](https://img.youtube.com/vi/RZ7bBIU8DRc/0.jpg)](https://www.youtube.com/watch?v=RZ7bBIU8DRc)

_Don't add Security, Remove Insecurity_, Mark Miller:

[![Don't add Security, Remove Insecurity](https://img.youtube.com/vi/u-XETUbxNUU/0.jpg)](https://www.youtube.com/watch?v=u-XETUbxNUU)

## Install

```sh
npm install ses
```

## Usage

The SES shim runs in most engines, either as an ESM module `ses` or as a
`<script>` tag.
For a script tag, the content encoding charset must be UTF-8, either by virtue
of `<head><meta charset="utf-8"></head>` (a general best practice for all HTML
files) or specifically `<script src="node_modules/ses/dist/ses.umd.min.js"
charset="utf-8">`.

SES can be bundled by Webpack, Browseriy, Rollup, and Parcel, but any of these
tools could be coopted with a supply-chain attack to invalidate the security
properties of SES.  We generally recommend installing SES as a separate script
tag.

### Lockdown

SES introduces the `lockdown()` function.
Calling `lockdown()` alters the surrounding execution environment, or
**realm**, such that no two programs running in the same realm can observe or
affect each other until they have been introduced, and even then can only
interact through their own exposed interfaces.

To do this, `lockdown()` tamper-proofs all of the JavaScript intrinsics, to
prevent **prototype pollution**.
After that, no program can subvert the methods of these objects (preventing
some **man in the middle attacks**).
Also, no program can use these mutable objects to pass notes to parties that
haven't been expressly introduced (preventing some **covert communication
channels**).

Lockdown freezes all objects that are effectively undeniable to programs in the
realm. The set of such objects includes but is not limited to: `globalThis`,
prototype objects of Array, Function, GeneratorFunction, and Object, and objects
accessible from those objects (such as `Object.prototype.toString`).

The `lockdown()` function also **tames** some objects including regular
expressions, locale methods, and errors.
A tamed `RegExp` does not have the deprecated `compile` method.
A tamed error does not have a V8 `stack`, but the `console` can still see the
stack.
Lockdown replaces locale methods like `String.prototype.localeCompare` with
generic versions that do not reveal the host locale.

```js
import 'ses';

lockdown();

console.log(Object.isFrozen([].__proto__));
// true
```

Lockdown does not erase any powerful objects from the initial global scope.
Instead, **Compartments** give complete control over what powerful objects
exist for client code.

See [`lockdown` options](docs/lockdown.md) for configuration options to
`lockdown`. However, all of these have sensible defaults that should
work for most projects out of the box.

### Harden

SES introduces the `harden` function.
*After* calling `lockdown`, the `harden` function ensures that every object in
the transitive closure over property and prototype access starting with that
object has been **frozen** by `Object.freeze`.
This means that the object can be passed among programs and none of those
programs will be able to tamper with the **surface** of that object graph.
They can only read the surface data and call the surface functions.

```js
import 'ses';

lockdown();

let counter = 0;
const capability = harden({
  inc() {
    counter++;
  },
});

console.log(Object.isFrozen(capability));
// true
console.log(Object.isFrozen(capability.inc));
// true
```

Note that although the **surface** of the capability is frozen, the capability
still closes over the mutable counter.
Hardening an object graph makes the surface immutable, but does not guarantee
that methods are free of side effects.


### Compartment

SES introduces the `Compartment` constructor.
A compartment is an evaluation and execution environment with its own
`globalThis` and wholly independent system of modules, but otherwise shares
the same batch of intrinsics like `Array` with the surrounding compartment.
The concept of a compartment implies an **initial compartment**, the initial
execution environment of a **realm**.

In the following example, we create a compartment endowed with a `print()`
function on `globalThis`.

```js
import 'ses';

lockdown();

const c = new Compartment({
  globals: {
    print: harden(console.log),
  },
  __options__: true, // temporary migration affordance
});

c.evaluate(`
  print('Hello! Hello?');
`);
```

The new compartment has a different global object than the start compartment.
The global object is initially mutable.
Locking down the realm hardened the objects in global scope.
After `lockdown`, no compartment can tamper with these **intrinsics** and
**undeniable** objects.
Many of these are identical in the new compartment.

```js
const c = new Compartment();
c.globalThis === globalThis; // false
c.globalThis.JSON === JSON; // true
```

Other pairs of compartments also share many identical intrinsics and undeniable
objects of the realm.
Each has a unique, initially mutable, global object.

```js
const c1 = new Compartment();
const c2 = new Compartment();
c1.globalThis === c2.globalThis; // false
c1.globalThis.JSON === c2.globalThis.JSON; // true
```

The global scope of every compartment includes a shallow, specialized copy of
the JavaScript intrinsics, disabling `Math.random`, `Date.now` and the
behaviors of the `Date` constructor which would reveal the current time.
Compartments leave these out since they can be used as covert communication
channels between programs.
However, a compartment may be expressly given access to these objects
through:

* the first argument to the compartment constructor or
* by assigning them to the compartment's `globalThis` after construction.

```js
const powerfulCompartment = new Compartment({
  globals: { Math },
  __options__: true, // temporary migration affordance
});
powerfulCompartment.globalThis.Date = Date;
```

### Compartment + Lockdown

Together, Compartment and lockdown isolate client code in an environment with
limited powers and communication channels.
A compartment has only the capabilities it is expressly given and cannot modify
any of the shared intrinsics.
Every compartment gets its own globals, including such objects as the
`Function` constructor.
Yet, compartment and lockdown do not break `instanceof` for any of these
intrinsics types!

All of the evaluators in one compartment are captured by that compartment's
global scope, including `Function`, indirect `eval`, dynamic `import`, and its
own `Compartment` constructor for child compartments.
For example, the `Function` constructor in one compartment creates functions
that evaluate in the global scope of that compartment.

```js
const c1 = new Compartment();
const f1 = new c.globalThis.Function('return globalThis');
f1() === c1.globalThis; // true

const c2 = new Compartment();
const f2 = new c.globalThis.Function('return globalThis');
f2() === c2.globalThis; // true

f1() === f2(); // false
```

Lockdown prepares for compartments with separate globals by freezing
their shared prototypes and replacing their prototype constructors
with powerless dummies.
So, `Function` is different in two compartments, `Function.prototype` is the
same, and `Function` is not the same as `Function.prototype.constructor`.
The `Function.prototype.constructor` can only throw exceptions.
So, a function passed between compartments does not carry access to
its compartment's globals along with it.
Yet, `f instanceof Function` works, even when `f` and `Function` are
from different compartments.

The `globalThis` in each compartment is mutable.
This can and should be frozen before running any dynamic code in that
compartment, yet is not strictly necessary if the compartment only
runs code from a single party.

### Modules

Any code executed within a compartment shares a set of module instances.
For modules to work within a compartment, the creator must provide
module descriptors.
A compartment can be configured with module descriptors, from highest to lowest
precedence:

- the `modules` map provided to the `Compartment` constructor,
- returned by a `moduleMapHook(specifier)` passed as an option to the
  `Compartment` constructor.
- returned by either the `importHook(specifier)` or `importNowHook(specifier)`
  option passed to the `Compartment` constructor. Calling
  `compartment.import(specifier)` falls through to the `importHook` which may
  return a promises, whereas `compartment.importNow(specifier)` falls through
  to the synchronous `importNowHook`.

The `resolveHook` determines how the compartment will infer the full module
specifier for another module from a referrer module and the import specifier.

```js
import 'ses';
import { ModuleSource } from '@endo/module-source';

const c1 = new Compartment({
  name: "first compartment",
  resolveHook: (moduleSpecifier, moduleReferrer) => {
    return resolve(moduleSpecifier, moduleReferrer);
  },
  importHook: async moduleSpecifier => {
    const moduleLocation = locate(moduleSpecifier);
    const moduleText = await retrieve(moduleLocation);
    return {
        source: new ModuleSource(moduleText, moduleLocation)
    };
  },
  __options__: true, // temporary migration affordance
});
```

> The Hardened JavaScript language specifies a global `ModuleSource`, but this
> is not provided by the shim because it entrains a full JavaScript parser that
> is an unnecessary performance penalty for the SES runtime.
> Instead, the SES shim accepts a pre-compiled module source duck-type that
> is tightly coupled to the shim implementation.

A compartment can also link a module in another compartment.

```js
const c2 = new Compartment({
  name: "second compartment",
  modules: {
    'c1': {
      source: './main.js',
      compartment: c1,
    },
  },
  resolveHook,
  importHook,
  __options__: true, // temporary migration affordance
});
```

#### Module Descriptors

Comparments can load and initialize module namespaces from module descriptors.
Like property descriptors, module descriptors are ordinary objects with various
forms.

##### Descriptors with `source` property

- If fhe value of the `source` property is a string, the parent compartment
  loads the module but the compartment itself initializes the module.

- Otherwise, if the value of the `source` property is the module source, the
  module is initialized from the module source.

- Otherwise, the value of the `source` property must be an object. The module
  is loaded and initialized from the object according to the [virtual module
  source](#VirtualModuleSource) pattern.

If the `importMeta` property is present, its value must be an object. The
default `importMeta` object is an empty object.

Compartments copy the `importMeta` object properties into the module
`import.meta` object like `Object.assign`.

If the `specifier` property is present, its value is coerced into a string and
becomes the referrer specifier of the module, on which all import specifiers
are resolved using the `resolveHook`.

##### Descriptors with `namespace` property

- If fhe value of the `namespace` property is a string, the descriptor shares a
  module to be loaded and initialized by the compartment referred by the
  `compartment` property.

    - If the `compartment` property is present, its value must be a
      compartment.
    - If absent, the `compartment` property defaults to the compartment being
      constructed in the `modules` option, or being hooked in the `loadHook`
      and `loadNowHook` options.

- Otherwise, if the value of the `namespace` property is a module namepace, the
  descriptor shares a module that is already available.

- Otherwise, the value of `namespace` property must be an object. The module is
  loaded and initialized from the object according to the [virtual module
  namespace](#VirtualModuleNamespace) pattern.

#### Redirects

If a compartment imports a module specified as `"./utility"` but actually
implemented by an alias like `"./utility/index.js"`, the `importHook` may
follow redirects, symbolic links, or search for candidates using its own logic
and return a module that has a different "response specifier" than the original
"request specifier".
The `importHook` may return an "alias" object with `source`, `compartment`,
and `specifier` properties.

- `source` must be a module source, either a virtual module source
  or a compiled module source.
- `compartment` is optional, to be specified if the alias transits to a
  the specified different compartment, and
- `specifier` is the full module specifier of the module in its compartment.
  This defaults to the request specifier, which is only useful if the
  compartment is different.

In the following example, the importHook searches for a file and returns an
alias.

```js
const importHook = async specifier => {
  const candidates = [specifier, `${specifier}.js`, `${specifier}/index.js`];
  for (const candidate of candidates) {
    const source = await maybeImportSource(candidate);
    if (source !== undefined) {
      return {
        source,
        specifier: candidate,
        compartment,
      };
    }
  }
  throw new Error(`Cannot find module ${specifier}`);
};

const compartment = new Compartment({
  resolveHook,
  importHook,
  __options__: true, // temporary migration affordance
});
```

#### moduleMapHook

The module map above allows modules to be introduced to a compartment up-front.
Some modules cannot be known that early.
For example, in Node.js, a package might have a dependency that brings in an
entire subtree of modules.
Also, a pair of compartments with cyclic dependencies between modules they each
contain cannot use `compartment.module` to link the second compartment
constructed to the first.
For these cases, the `Compartment` constructor accepts a `moduleMapHook` option
that is like the dynamic version of the static `moduleMap` argument.
This is a function that accepts a module specifier and returns the module
namespace for that module specifier, or `undefined`.
If the `moduleMapHook` returns `undefined`, the compartment proceeds to the
`importHook` to attempt to asynchronously obtain the module's source.

```js
const moduleMapHook = moduleSpecifier => {
  if (moduleSpecifier === 'even') {
    return {
      source: './index.js',
      compartment: even,
    };
  } else if (moduleSpecifier === 'odd') {
    return {
      source: './index.js',
      compartment: odd,
    };
  }
};

const even = new Compartment({
  resolveHook: nodeResolveHook,
  importHook: makeImportHook('https://example.com/even'),
  moduleMapHook,
  __options__: true, // temporary migration affordance
});

const odd = new Compartment({
  resolveHook: nodeResolveHook,
  importHook: makeImportHook('https://example.com/odd'),
  moduleMapHook,
  __options__: true, // temporary migration affordance
});
```

#### importNowHook

Additionally, an `importNowHook` may be provided that the compartment will use
as means to synchronously load modules not seen before in situations where
calling out to asynchronous `importHook` is not possible.
Specifically, when `compartmentInstance.importNow('specifier')` is called, the
compartment will first look up module records it's already aware of and call
`moduleMapHook` and if none of that is successful in finding a module record
matching the specifier, it will call `importNowHook` expecting to synchronously
receive the same record type as from `importHook` or throw if it cannot.

```js
import 'ses';
import { ModuleSource } from '@endo/module-source';

const compartment = new Compartment({
  name: "first compartment",
  modules: {
    c: {
      source: new ModuleSource(''),
    },
  },
  resolveHook: (moduleSpecifier, moduleReferrer) => {
    return resolve(moduleSpecifier, moduleReferrer);
  },
  importHook: async moduleSpecifier => {
    const moduleLocation = locate(moduleSpecifier);
    const moduleText = await retrieve(moduleLocation);
    return {
      source: new ModuleSource(moduleText, moduleLocation),
    };
  },
  importNowHook: moduleSpecifier => {
    const moduleLocation = locate(moduleSpecifier);
    // Platform-specific synchronous read API can be used
    const moduleText = fs.readFileSync(moduleLocation);
    return {
      source: new ModuleSource(moduleText, moduleLocation),
    };
  },
  __options__: true, // temporary migration affordance
});
//...                   | importHook | importNowHook
await compartment.import('a'); //| called     | not called
compartment.importNow('b');    //| not called | called
compartment.importNow('a');    //| not called | not called
compartment.importNow('c');    //| not called | not called
```

### <a name="VirtualModuleSource"></a> Virtual Module Source

To incorporate modules not implemented as JavaScript modules, third-parties may
implement a `VirtualModuleSource` interface.
The object must have an `imports` array and an `execute` method.
The compartment will call `execute` with:

1. the proxied `exports` namespace object,
2. a `resolvedImports` object that maps import names (from `imports`) to their
   corresponding resolved specifiers (through the compartment's `resolveHook`),
   and
3. the `compartment`, such that `importNow` can obtain any of the module's
   specified `imports`.

:warning: A future breaking version may allow the `importNow` and the `execute`
method of virtual module sources to return promises, to support
top-level await.

:warning: The virtual module source interface does not yet agree with the
[XS](https://www.moddable.com/hardening-xs) implementation of [Hardened
JavaScript](https://hardenedjs.org/).

### Compiled modules

Instead of the `ModuleSource` constructor specified for the SES language,
the SES shim uses compiled module source records as a stand-in.
These can be created with a `ModuleSource` constructor from a package
like `@endo/module-source`.
We omitted `ModuleSource` from the SES shim because it entrains a heavy
dependency on a JavaScript parser.
The shim depends upon a `ModuleSource` constructor to analyze and
transform the source of a JavaScript module (known as an ESM or a `.mjs` file)
into a JavaScript program suitable for evaluation with `compartment.evaluate`
using a particular calling convention to initialize a module instance.

A compiled module source record has the following shape:

- `imports` is a record that maps partial module specifiers to a list of
  names imported from the corresponding module.
- `exports` is an array of all the names that the module will export.
- `reexports` is an array of partial module specifier for which this
  module exports all imported names.
  This field is optional.
- `__syncModuleProgram__` is a string that evaluates to a function that accepts
  an initialization record and initializes the module.
  This property distinguishes this type of module record.
  The name implies a future record type that supports top-level await.
  - An initialization record has the properties `imports`, `liveVar`, `importMeta` and
    `onceVar`.
    - `imports` is a function that accepts a map from partial import
      module specifiers to maps from names that the corresponding module
      exports to notifier functions.
      A notifier function accepts an update function and registers
      to receive updates for the value exported by the other module.
    - `importMeta` is a null-prototype object with keys transferred from `importMeta`
      property in the envelope returned by importHook and/or mutated by
      calling `importMetaHook(moduleSpecifier, importMeta)`
    - `liveVar` is a record that maps names exported by this module
      to a function that may be called to initialize or update
      the corresponding value in another module.
    - `onceVar` is a record that maps constants exported by this
      module to a function that may be called to initialize the
      corresponding value in another module.
- `__syncModuleFunctor__` is an optional function that if present is used
  instead of the evaluation of the `__syncModuleProgram__` string. It will be
  called with the initialization record described above. It is intended to be
  used in environments where eval is not available. Sandboxing of the functor is
  the responsibility of the author of the ModuleSource.
- `__liveExportsMap__` is a record that maps import names or names in the lexical
  scope of the module to export names, for variables that may change after
  initialization. Any reexported name is assumed to possibly change.
  The exported name is wrapped in a duple array like `["exportedName", true]`.
  The second value, a boolean, indicates that the variable has a temporal
  dead-zone (a time between creation and initialization) when access to that
  name should throw a `ReferenceError`.
- `__fixedExportsMap__` is a record that maps import names to export names
  for constants exported by this module.
  The fixed exports map is an aesthetic subtype of the live exports map,
  so the value is wrapped in a simple array like `["exportedName"]`

### Transforms

The `Compartment` constructor accepts a `transforms` option.
This is an array of JavaScript source to source translation functions,
in the order they should be applied.
Passing the source to the first function's input, then from each function's
output to the next's input, the final function's output must be a valid
JavaScript "Program" grammar construction, code that is valid in a `<script>`,
not a module.

```js
const transforms = [addCodeCoverageInstrumentation];
const c = new Compartment({
  globals: { console, coverage },
  transforms,
  __options__: true, // temporary migration affordance
});
c.evaluate('console.log("Hello");');
```

The `evaluate` method of a compartment also accepts a `transforms` option.
These apply before and in addition to the compartment-scoped transforms.

```js
const transform = source => source.replace(/Farewell/g, 'Hello');
const transforms = [transform];
c.evaluate('console.log("Farewell, World!")', { transforms });
// Hello, World!
```

These transforms do not apply to modules.
To transform the source of a JavaScript module, the `importHook` must
intercept the source and transform it before passing it to the
`ModuleSource` constructor.
These are distinct because programs and modules have distinct grammar
productions.

An **internal implementation detail** of the SES-shim is that it
converts modules to programs and evaluates them as programs.
So, only for this implementation of `Compartment`, it is possible for a program
transform to be equally applicable for modules, but that transform will
have a window into the internal translation, will be sensitive to changes to
that translation between any pair of releases, even those that do not disclose
any breaking changes, and will only work on SES-shim, not any other
implementation of `Compartment` like the one provided by XS.

The SES-shim `Compartment` constructor accepts a `__shimTransforms__`
option for this purpose.
For the `Compartment` to use the same transforms for both evaluated strings
and modules converted to programs, pass them as `__shimTransforms__`
instead of `transforms`.

```js
const __shimTransforms__ = [addCoverage];
const c = new Compartment({
  globals: { console, coverage },
  __shimTransforms__,
  __options__: true, // temporary migration affordance
});
c.evaluate('console.log("Hello");');
```

The `__shimTransforms__` feature is designed to uphold the security properties
of compartments, since an attacker may use all available features, whether they
are standard or not.

### Logging Errors

`lockdown()` adds new global `assert` and tames the global `console`. The error
taming hides error stacks, accumulating them in side tables. The `assert`
system generates other diagnostic information hidden in side tables. The tamed
console uses these side tables to output more informative diagnostics.
[Logging Errors](./src/error/README.md) explains the design.

## Security claims and caveats

The `ses` shim concerns boundaries between programs in the same process and
JavaScript realm.
In terms of the [Taxonomy of Security Issues](https://papers.agoric.com/taxonomy-of-security-issues/),
the `ses` shim creates a boundary that is finer than an operating system
process or thread and facilitates boundaries as fine as individual objects.
While `ses` can interpose at granularities where process isolation is not a
viable boundary, as between an application and its dependencies or between a
platform and a plugin, `ses` combines well with coarser boundaries for defense
in depth.

For the purposes of these claims and caveats, a "host program" is a program
that arranges `ses`, calls `lockdown`, and orchestrates one or more "guest
programs", providing limited access to its resources.

### Single-guest Compartment Isolation

Provided that the `ses` implementation and its
[trusted compute base](#trusted-compute-base) are correct, we claim that a host
program can evaluate a guest program (`program`) in a compartment after
`lockdown` and that the guest program:

- will initially only have access to one mutable object, the compartment's
  `globalThis`,
- specifically cannot modify any shared primordial objects, which are part of
  the default execution environment,
- cannot initially perform any I/O (except I/O necessarily performed by the
  trusted compute base like paging virtual memory),
- and specifically cannot measure the passage of time at any resolution.

However, such a program can:

- execute for an indefinite amount of time,
- allocate arbitrary amounts of memory,
- detect the platform endianness,
- in some JavaScript engines, observe the contents of the stack.
  This may include sensitive information about the layout of files on the host
  disk.
  In cases where the stack is data-dependent, a guest can infer the data.
  `ses` occludes the stack on V8 and SpiderMonkey, but cannot on
  JavaScriptCore.

```js
lockdown();
const compartment = new Compartment();
compartment.evaluate(program);
```

### Multi-guest Compartment Isolation

If the host program arranges for the compartment's `globalThis` to
be frozen, we additionally claim that the host can evaluate any two guest
programs (`program1` and `program2`) in that compartment such that neither
guest program will:

- initially share *any* mutable objects.
- be able to observe the relative passage of time of the other program,
  as they would had they been given a reference to a working `Date.now()`.
- be able to communicate, as they would if they had shared access to mutable
  state like an unfrozen object, a hardened collection like a `Map`, or even
  `Math.random()`.

```js
lockdown();
const compartment = new Compartment();
harden(compartment.globaThis);
compartment.evaluate(program1);
compartment.evaluate(program2);
```

### Endowment Protection

The above `program`, `program1`, and `program2` guest programs are only useful
as glorified calculators.
When going beyond that by "endowing" a compartment with extra objects, a host
program is responsible for maintaining any of the invariants above that it
considers necessary.

For example, a host program may run two guest programs in separate
compartments, giving one the ability to resolve a promise and the other
the ability to observe the settlement (fulfillment or rejection) of
that promise.
The host program is responsible for hardening the objects implementing such
abilities.

```js
lockdown();

const promise = new Promise(resolve => {
  const compartmentA = new Compartment({
    globals: harden({ resolve }),
  __options__: true, // temporary migration affordance
  });
  compartmentA.evaluate(programA);
});

const compartmentB = new Compartment({
  globals: harden({ promise }),
  __options__: true, // temporary migration affordance
});
compartmentB.evaluate(programB);
```

With `ses`, guest programs are initially powerless.
A host can explicitly share limited powers with guest programs
and provide intentional communication channels between them.

### Caveats

Host programs must maintain the `ses` boundary with care in what they present
as endowments.
A host program should take care not to share mutable state with guests,
or distribute mutable state to multiple guests, such as an object that has not
been frozen with `harden` or a collection like a `Map` or `Set` or typed array
(collections retain some mutability even if hardened).

For the purposes of sharing state, pseudo-random number generators (PRNG) like
`Math.random()` are equivalent to read and write access to shared state, and
any guest can use one to eavesdrop on other guests or the host that share one.

If a guest program needs a high resolution timer to function, the host should
only invite one guest to a single operating system process and limit the
activity of the host program in the same process.

Hosts must avoid exposing `SharedArrayBuffer` to guests.
Any two JavaScript programs sharing a `SharedArrayBuffer` can use the shared
buffer to construct a high resolution timer.

The `ses` shim does not in itself isolate the stack of guest programs, even
when evaluated in separate compartments.
This is relevant when objects are shared between guest programs.

When a program interacts with an object introduced by another program (as
through the per-compartment `globalThis`, function arguments or returned
values), there are potential risks due to the synchronous nature of object
access.
Even interactions that are not explicit function calls may cause code from
another program, like property accessors or proxy traps, to execute on the same
stack, which may be able to detect the stack height, throw an exception, or call
back into the program in pursuit of a reentrancy attack.

A host object can defend itself from reentrancy attacks by ensuring that it
interacts with guest objects on a clean stack through the use of promises.

Within these constraints, a host program can provide objects that grant limited
I/O capabilities to guest programs, and even revoke or suspend those
capabilities at runtime.

### Trusted Compute Base

The trusted compute base (TCB) for `ses` includes:

- the host hardware,
- the host operating system,
- any intermediate virtual operating systems or hypervisors,
- the process memory manager,
- an implementation of JavaScript conforming to ECMAScript 262 as of
  2021, providing no unspecified embedding host behavior like the introduction of syntax
  that when evaluated reveals a mutable object.
  `ses` accounts for one such host behavior provided by Node.js, namely the `domain`
  property on promises, by preventing the use of `ses` in concert with the
  `domain` module.
- Also, any attached debugger, and
- any JavaScript that has executed in the same realm before the host program calls
  `lockdown`, including JavaScript that executes after `ses` initializes.

## Audits

In June 2021, `ses` underwent formal third party vulnerability assessment over a
period of 4 weeks with 3 engineers and a dedicated project manager that
surfaced no unknown security issues or vulnerabilities within the code. As a
result of this assessment, [a single code change was
made](https://github.com/endojs/endo/issues/126) to set a flag to disable the
domain module in Node.js to mitigate a known issue identified in the code.  The
code will be the subject of another round of intense application security
review mid-2022 by a reputable application security firm renowned for their
results in security reviews.

In July 2021, `ses` was the target of an intensive collaborative bug hunt lead by
the MetaMask team.
No critical flaws in the code surfaced during the review.
As a result of the search for flaws, deficiencies, and weaknesses in the code,
a series of small code changes and documentation improvements were made. There
is a report available on the
[Agoric blog](https://agoric.com/blog/technology/purple-teaming-how-metamask-and-agoric-hunted-bugs-to-harden-javascript)
that includes links to recordings of code walk-throughs and technical
discussion, and issues are tagged
[audit-SEStival](https://github.com/endojs/endo/issues?q=label%3Aaudit-sestival).
The [video recordings of the MetaMask and Agoric collaborative
review](https://www.youtube.com/playlist?list=PLzDw4TTug5O2d1XOdB7VNCZbIxRZu3gov).
provide useful background for future audits, reviews, and for learning more
about how the `ses` shim constructs a Hardened JavaScript environment.

In addition to vulnerability assessments, active efforts to [formally verify
the Agoric kernel](https://agoric.com/blog/technology/the-path-to-verified-blds-how-informal-systems-and-agoric-are-using-formal)
have found the object capability model that `ses` provides to be sound.

Hardened JavaScript is also within the scope of the [Agoric bug bounty
program](https://hackerone.com/agoric), which rewards researchers for surfacing valid
bugs in our code. We welcome the opportunity to cooperate with researchers,
whose efforts will undoubtedly yield stronger, more resilient code.

## Bug Disclosure

Please help us practice coordinated security bug disclosure, by using the
instructions in [SECURITY.md][] to report security-sensitive bugs privately.

For non-security bugs, please use the [regular Issues page][SES Issues].

## Ecosystem Compatibility

Most ordinary JavaScript can run without issues in a realm locked down by SES.
Exceptions are tracked at [issue #576][incompatibility tracking], and almost
always take the form of assignments that fail because the
"[override mistake][override mistake]" prevents overriding properties inherited
from a frozen intrinsic object in the prototype chain. When that is the case,
the code is often incompatible with *all* environments in which intrinsic
objects are frozen (such as in Node.js with the
[`--frozen-intrinsics`][Node frozen intrinsics] option) and can be fixed by
replacing `<lhs>.<propertyKey> = <rhs>;` or `<lhs>[<propertyKey>] = <rhs>;` with
```js
Object.defineProperties(<lhs>, {
  [<propertyKey>]: {
    value: <rhs>,
    writable: true,
    enumerable: true,
    configurable: true,
  },
});
```

Upon encountering an incompatibility, we recommend that you add a comment to
[issue #576][incompatibility tracking] and file an issue with the external
project referencing this section.
Projects often have their own unique issue reporting templates, but generally
provide some place to include text like

> ```
> This project has some assignments that break in an environment with frozen
> intrinsic objects, such as
> [Hardened JS (a.k.a. SES)](https://github.com/endojs/endo/blob/master/packages/ses#ecosystem-compatibility)
> or Node.js with the
> [`--frozen-intrinsics`](https://nodejs.org/docs/latest/api/cli.html#--frozen-intrinsics)
> option.
> Specifically, [link to source in the project] does not work correctly in such
> an environment.
>
> Please consider increasing support by replacing assignments to object
> properties inherited from intrinsics with use of `Object.defineProperties`
> (thereby working around the JavaScript "override mistake"), and if applicable
> also by avoiding mutation of intrinsic objects.
> If you don't have the capacity but would accept a PR, please comment to that
> effect so that a volunteer knows their efforts would be welcomed.
> ```

We find that library authors are generally amenable to making these small changes to increase
compatibility with any environment that protects itself from prototype pollution attacks by freezing
intrinsics, including `ses`.

[Hardened JavaScript]: https://hardenedjs.org/
[define shim]: https://en.wikipedia.org/wiki/Shim_(computing)
[Endo Matrix]: https://matrix.to/#/#endojs:matrix.org
[incompatibility tracking]: https://github.com/endojs/endo/issues/576
[Node frozen intrinsics]: https://nodejs.org/docs/latest/api/cli.html#--frozen-intrinsics
[override mistake]: https://web.archive.org/web/20141230041441/http://wiki.ecmascript.org/doku.php?id=strawman:fixing_override_mistake
[SECURITY.md]: https://github.com/endojs/endo/blob/master/packages/ses/SECURITY.md
[SES Issues]: https://github.com/endojs/endo/issues
[SES proposal]: https://github.com/tc39/proposal-ses
[SES Strategy Group]: https://groups.google.com/g/ses-strategy
[SES Strategy Recordings]: https://www.youtube.com/playlist?list=PLzDw4TTug5O1jzKodRDp3qec8zl88oxGd

-----END FILE ses/README.md-----
-----BEGIN FILE skel/README.md-----


-----END FILE skel/README.md-----
-----BEGIN FILE stream-node/README.md-----
# Endo / Node Stream Adapters

This package provides `makeNodeReader` and `makeNodeWriter` adapters that adapt Node.js Reader and Writer to Endo's async iterable streams.

-----END FILE stream-node/README.md-----
-----BEGIN FILE stream/README.md-----
# Endo Streams

Endo models streams as hardened async iterators.
Async iterators are sufficient to model back-pressure or pacing
since they are channel messages both from producer to consumer
and consumer to producer.
Streams are therefore symmetric.
The same stream type serves for both a reader and a writer.

These streams depend on full Endo environment initialization, as with `@endo/init`
to ensure that they are run in Hardened JavaScript with remote promise support
(eventual send).

## Writing

To write to a stream, give a value to the next method.

```js
// ...
await writer.next(value);
```

Awaiting the returned promise slows the writer to match the pace of the reader.

## Reading

To read from a stream, await the value returned by the next method.

```js
for await (const value of reader) {
  // ...
}
```

## Map

To map a reader to a reader through a synchronous value transform, use `mapReader`.

```js
const doubleReader = mapReader(singleReader, n => n * 2);
```

In this example, any value read from doubleReader will be double what was read
from singleReader.

To map a writer to a writer through a synchronous value transform, use
`mapWriter`.

```js
const singleWriter = mapWriter(doubleWriter, n => n * 2);
```

In this example, any value written to singleWriter will be writ double to
doubleWriter.

## Pipe

The `makePipe` function returns an entangled pair of streams.
Use one as a reader and the other as a writer.
Pipes are useful for mocking streams in tests.

```js
const [writer, reader] = makePipe();
```

Pipes use `makeStream` and `makeQueue`.
`makeQueue` creates an async promise queue: a collection type like a queue
except that `get` returns a promise and `put` accepts a promise, so `get` can
be called before `put`.
An async queue ensures that the promises returned by `get` and accepted by
`put` are matched respectively, but provides no guarantee about the order in
which promises settle.
A stream is consequently a pair of queues that transport iteration results,
one to send messages forward and another to receive acknowledgements.

## Pump

The `pump` function pumps iterations from a reader to a writer.
The pump must be primed with the first acknowledgement to send to the reader,
typically `undefined`, as in `reader.next(undefined)`.
This makes the parity of a pump "odd", because the reader needs a free
acknowledgement to start.
This is in contrast to a pipe, which has "even" parity, because the reader and
writer can both proceed initially.

So, for example, we can implement `cat` in Node.js by pumping stdin to stdout.

```js
import { makeNodeWriter, makeNodeReader } from '@endo/stream-node';

const writer = makeNodeWriter(process.stdout);
const reader = makeNodeReader(process.stdin);
await pump(writer, reader);
```

## Prime

Async generator functions are very useful for making reader adapters.

```js
async function *double(reader) {
  for await (const value of reader) {
    yield value * 2;
  }
  return undefined;
}
```

However, async generator functions can also serve as writers, because `yield`
evaluates to the argument passed to `next`.
However, generator writers have odd parity, meaning the first value sent to a
generator function has nowhere to go and gets discarded as the program counter
proceeds from the beginning of the function to the first `yield`, `return`, or
`throw`.

The `prime` function compensates for this by sending a primer to the generator
once.

```js
async function *logGenerator() {
  for (;;) {
    console.log(yield);
  }
}

const writer = prime(logGenerator());
await writer.next('First message is not discarded');
```

## Hardening

This library depends on Hardened JavaScript.
The environment must be locked down before initializing this library.
All of the exported functions and the streams they produce are hardened.

This implementation of streams ensures that iteration results are shallowly
frozen.
The user is responsible for hardening the transported values if that is their
intent.
Some values like array buffers cannot be frozen.

-----END FILE stream/README.md-----
-----BEGIN FILE syrup/README.md-----
# Syrup

🚧 Work in progress.

[Syrup](https://gitlab.com/spritely/syrup) is an binary object marshalling
codec.

This is a partial implementation of Syrup intended to be future-compatible and
strictly canonical.

- Single point IEEE floating point, with the "F" prefix, is unsupported because
  JavaScript cannot canonically write any kind of floating point number except
  a double precision 64 bit float.
- A future version might introduce `null` or `undefined`, possibly both, either
  as a record kind supported at a higher layer, or as a single character
  optimization.
- A future version might support symbols as JavaScript registered symbols.
- Future versions cannot support Syrup Dictionaries with non-string keys.
- A future version might support Syrup Sets as JavaScript Sets with some
  limitation on what keys are expressible.
- A future version might support Syrup Maps as JavaScript Maps, provided Syrup
  adds a notation for Maps.
  To do this, the Syrup implementation might need to be coupled to
  a higher layer protocol like CapTP, where some record traps are built
  into the codec, since passing a dictionary (with only string keys)
  to a record trap would not be sufficient to express other types of keys.
- A future version might support Syrup records.

The supported encoding consists of:

- Syrup booleans: `t` or `f`,
  as JavaScript `true` and `false`
- Syrup double flonum:
  `D` _big endian IEEE double precision float (64 bits)_,
  as JavaScript `number`
- Syrup signed integers:
  _whole integer_ `+` or _positive int_ `-`,
  like `0+` or `1-`,
  as JavaScript `bigint`
- Syrup byte strings:
  _whole integer byte length prefix_ `:` _bytes_,
  like `3:cat`,
  as JavaScript `Uint8Array`
- Syrup strings:
  _whole integer byte length prefix_ `"` _UTF-8 encoded bytes_,
  like `3"cat`,
  as JavaScript `string`
- Syrup dictionary:
  `{` _zero or more alternating_ _syrup encoded string key_ _syrup encoded any
  value_ `}`,
  as frozen JavaScript record objects
- Syrup lists:
  `[` _zero or more syrup encoded values_ `]`
  as frozen JavaScript arrays

-----END FILE syrup/README.md-----
-----BEGIN FILE test262-runner/README.md-----
# test262-runner

Run ECMAScript compliance tests on Node.js, XS, and potentially others, with a
prelude that shims Hardened JavaScript on these platforms.

## Test262 subset

The `test262` directory contains

* a copy of the `tests` and `harness` directories from https://github.com/tc39/test262.
* additional tests from https://github.com/Moddable-OpenSource/moddable
* additional Hardened JavaScript tests

We currently only run tests expressly marked with the `ses-xs-parity` feature
in their front-matter.

## Justification

Maintaining a local copy of tests taken at a given revision provides not only stability, it's also much faster on autobuilds than having to both checkout the test262 git repo and filter for relevant tests, and having to do so at every test run.

This technique is the same used by all major JavaScript engines:
- https://github.com/WebKit/webkit/tree/master/JSTests/test262
- https://github.com/v8/v8/tree/master/test/test262
- https://github.com/mozilla/gecko-dev/tree/master/js/src/tests/test262
etc.

-----END FILE test262-runner/README.md-----
-----BEGIN FILE trampoline/README.md-----
# @endo/trampoline

> Multicolor trampolining using generators

**@endo/trampoline** is a utility library which helps share code between synchronous and asynchronous variations of the same algorithm.

## Example Usage

```js
import { asyncTrampoline, syncTrampoline } from '@endo/trampoline';

/**
 * This function "reads a file synchronously" and returns "a list of its imports"
 *
 * @param {string} filepath Source file path
 * @returns {string[]} List of imports found in source
 */
const findImportsSync = filepath => {
  // read a file, parse it for imports, return a list of import specifiers
  // (synchronously)
  // ...
};

/**
 * This function "reads a file asynchronously" and returns "a list of its imports"
 *
 * @param {string} filepath Source file path
 * @returns {Promise<string[]>} List of imports found in source
 */
const findImportsAsync = async filepath => {
  // read a file, parse it for imports, return a list of import specifiers
  // (asynchronously)
  // ...
};

/**
 * Recursively crawls a dependency tree to find all dependencies
 *
 * @template {string[] | Promise<string[]>} TResult Type of result (list of imports)
 * @param {(filepath: string) => TResult} finder Function which reads a file and returns its imports
 * @param {string} filename File to start from; entry point
 * @returns {Generator<TResult, string[], string[]>} Generator yielding list of imports
 */
function* findAllImports(finder, filename) {
  // it doesn't matter if finder is sync or async!
  let specifiers = yield finder(filename);

  // pretend there's some de-duping, caching,
  // scrubbing, etc. happening here

  for (const specifier of specifiers) {
    // it's okay to be recursive
    specifiers = [...specifiers, ...(yield* findAllImports(finder, specifier))];
  }
  return specifiers;
}

// results are an array of all imports found in some.js' dependency tree
const asyncResult = await asyncTrampoline(
  findAllImports,
  findImports,
  './some.js',
);

// same thing, but synchronously
const syncResult = syncTrampoline(
  findAllImports,
  findImportsAsync,
  './some.js',
);

asyncResult === syncResult; // true
```

In the above example, **@endo/trampoline** allows us to re-use the operations in `loadRecursive()` for _both_ sync and async execution. An implementation _without_ **@endo/trampoline** would need to duplicate the operations into two (2) discrete recursive functions—a synchronous-colored function and an asynchronous-colored function. Over time, this situation commonly leads to diverging implementations. If that _doesn't_ sound like a big deal for _whatever you're trying to do here_, then you probably don't need **@endo/trampoline**.

## What is this?

The pattern exposed by this library—known as [trampolining][]—helps manage control flow in a way that avoids deep recursion and potential stack overflows.

**@endo/trampoline** provides the trampolining pattern, but in such a way that a consumer can execute _either_ synchronous _or_ asynchronous operations _paired with operations common to both_.

In other words, **@endo/trampoline** can help _reduce code duplication_ when operations must be executed _in both sync and async_ contexts.

## Install

The usual sort of thing:

```sh
npm install @endo/trampoline
```

## License

Apache-2.0

## Disclaimer

By using this library, you agree to indemnify and hold harmless the authors of `@endo/trampoline` from any and all losses, liabilities and risk of bodily injury _including but not limited to_ broken bones, sprains, bruises or other hematomas, fibromas, teratomas, mesotheliomas, cooties, bubonic plague, psychic trauma or warts due to the inherent danger of trampolining.

[trampolining]: https://raganwald.com/2013/03/28/trampolines-in-javascript.html

-----END FILE trampoline/README.md-----
-----BEGIN FILE where/README.md-----
# Where is Endo?

This package provides a utility for finding the user files and Unix domain
socket or Windows named pipe for the Endo daemon.
The Endo user directory stores the per-user runtime data for Endo,
including logs and other application storage.

Endo attempts to use or infer [Cross-desktop XDG conventions][XDG] paths in
every meaningful way.
Windows named pipes do not appear to fit this model.
Otherwise falls back to the native conventions on Windows and Mac/Darwin.
On Windows, Endo does not use separate state and cache directories and does not
yet sync state between home directories.

[XDG]: https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html

-----END FILE where/README.md-----
-----BEGIN FILE zip/README.md-----
# Endo Zip

This is a modernization and specialization of [JSZip][] (MIT License) that has
no dependencies on any built-in modules and is entirely implemented with
ECMAScript modules.  This makes the library suitable for embedding in an XS
binary, bundling for any platform with Rollup, and usable with `node -r esm`.

Modernization afforded the opportunity to focus on use of TypedArrays and UTF-8
without reservation, and to use TypeScript JSDoc comments to verify the flow of
information.  It also afforded an opportunity to make some security-conscious
decisions, like treating file name spoofing as an integrity error and
requiring a date to be expressly provided instead of reaching for the ambient
original Date constructor, which will pointedly be absent in constructed
compartments in locked-down environments.

Zip format allows for an arbitrary-length comment and an arbitrary number of
Zip64 headers in the "end of central directory block".
Zip implementations must therefore scan backward from the end for the magic
numbers that introduce the "EOCDB".
However, a specially crafted Zip file may contain those magic numbers
before the end.

So, for security, this specialized library does not support Zip64 nor
the variable width archive comment.
With some difficulty, Zip64 might be recovered by scanning backward from the
end of the file until we find a coherent EOCDB with no trailing bytes.
Even careful support for the variable width comment at the end of the archive
would always allow for the possibility of a comment that is itself a valid Zip
file with a long prefix, since Zip files allow an arbitrary length prefix.

For expedience, the specialization dropped support for INFLATE compression.
The dependency would need to be converted to ECMAScript modules, which is not
much effort. Pursuing that intent, one should factor out the shared CRC32
module.

JSZip supports an asynchronous mode, that despite the name, is not concurrent.
The mode is intended to keep the main thread lively while emitting progress
reports.  For expedience, this mode is omitted, but could be restored using the
same underlying utilities, and I expect async/await and async iterators would
make the feature easier to maintain.

Provided an async seekable reader, a lazy Zip reader could be built on the same
foundations, deferring decompression and validation until the file is opened.

For expedience, support for streaming compression and the necessary data
descriptors have been dropped.  They are not necessary for synchronous writing.
The data descriptors are also redundant with the central directory for reading,
so they've been omitted, though recovering them for additional integrity
checks would be useful.

For expedience, explicit directory records are ignored on read and omitted on
write.  These would also be straightforward to recover.

For expedience, there is no API for enumerating the contents of the archive.
This would be straightforward to implement.

 [JSZip]: https://github.com/Stuk/jszip

-----END FILE zip/README.md-----

---

### Message ID: 3702abde-5512-4742-aa34-1c738711f851
**Author**: tool

**Content:**

Reflecting on the user query. They seek a TS code snippet for NodeJS using Endo. It should download a TypeScript module and run it in a SES compartment, leveraging updated docs from compartment-mapper and Endo.

**Integrating remote code**

I’m combining and gathering remote TypeScript code in a NodeJS environment, ensuring it runs correctly using SES.

**Weighing improvements**

I'm considering integrating debugging tools, sourceMap handling, and `importMeta` functionalities to enhance the system further, ensuring it aligns with the latest compartment-mapper and Endo documentation.

**Enhancing debugging**

I’m working on incorporating `importMetaHook` and `computeSourceMapLocation` to improve remote code debugging and retrieval in a NodeJS environment. Additionally, considering integrating handling for `policy`, `globals`, and `modules`.

**Integrating source map handling**

I’m pulling in `computeSourceMapLocation` from `import-bundle` to enhance debugging capabilities by seamlessly incorporating it into `importLocation` as part of the `powers` argument.

**Enhancing code handling**

I'm expanding type declaration support and refining code management with `conditions: ['endo']`. This adjustment will guide `importLocation` towards `endo`.

**Pulling together functionality**

I'm incorporating `importMetaHook` and `computeSourceMapLocation` into `importLocation`, adding `policy`, setting `conditions: ['endo']`, and refining error handling. This enhances remote code management capabilities.

---

### Message ID: 9ce0ff66-ca31-4cab-97ee-28453c9c3248
**Author**: assistant

**Content:**

Below is an improved version of the previous TypeScript file, incorporating additional features and insights from the Endo documentation. These include setting `importMetaHook` to populate `import.meta.url` for the module, providing a `computeSourceMapLocation` hook for debugging with source maps, and retaining the languageForExtension mapping for `.ts` files. The code also demonstrates how to supply a `console` global and leave room for adding policies or transforms if needed.

```typescript
// run-remote-module.ts
import 'ses';
import fetch from 'node-fetch';
import { importLocation } from '@endo/compartment-mapper';
import { computeSourceMapLocation } from '@endo/import-bundle/source-map-node.js';

// Lock down the environment with verbose stack traces for easier debugging
lockdown({ errorTaming: 'unsafe', stackFiltering: 'verbose' });

const loadAndRun = async (moduleURL: string) => {
  const packageURL = new URL('./package.json', moduleURL).toString();

  const read = async (location: string): Promise<Uint8Array> => {
    if (location === packageURL) {
      // Minimal package.json: treat all .ts as ESM
      const pkg = {
        name: "remote-module",
        type: "module",
        main: new URL(moduleURL).pathname.replace(/^\/+/, '')
      };
      return new TextEncoder().encode(JSON.stringify(pkg));
    } else {
      const res = await fetch(location);
      if (!res.ok) {
        throw new Error(`Failed to fetch ${location}: ${res.statusText}`);
      }
      const content = await res.arrayBuffer();
      return new Uint8Array(content);
    }
  };

  // Provide limited globals and no extra modules by default
  const globals = { console };
  const modules = {};

  // Map .ts files to ESM
  const languageForExtension = { ts: 'mjs' };

  // Hook to set import.meta.url for debugging & referencing
  const importMetaHook = (moduleSpecifier: string, importMeta: Record<string, unknown>) => {
    importMeta.url = moduleSpecifier;
  };

  // Optionally handle source maps for better debugging experience
  // Adjust computeSourceMapLocation as needed for your environment
  const { namespace } = await importLocation(
    read,
    moduleURL,
    {
      globals,
      modules,
      languageForExtension,
      importMetaHook,
      computeSourceMapLocation(details) {
        // For debugging: return a URL for the source maps
        return `file://${details.location}`;
      },
      // In case you want to apply transforms to code, you could add:
      // transforms: [yourTransformFunction]
      // or __shimTransforms__ if you need to instrument modules
      //
      // If you want to apply policies, you could do:
      // policy: yourPolicyObject
    }
  );

  console.log('Loaded module exports:', namespace);
};

loadAndRun('https://example.com/yourModule.ts').catch(err => {
  console.error(err);
  process.exit(1);
});
```

**Key Improvements:**

1. **importMetaHook:** Populates `import.meta.url` for modules, helpful for modules that rely on `import.meta` for resource location or debugging.

2. **computeSourceMapLocation:** Integrates source maps for easier local debugging. This is particularly useful if you transform or bundle code before evaluation.

3. **languageForExtension:** Ensures `.ts` files get treated as ESM modules. This aligns with the `@endo/compartment-mapper` docs for TypeScript integration.

4. **Globals and Modules:** Demonstrates how to provide a limited global environment and how to supply platform features selectively. Additional `modules` or endowments (like `fs`, `fetch`, or a controlled PRNG) can be included if needed.

5. **Comments for Future Enhancements:** Leaves hooks for adding transforms, policies, or other features described in the Endo docs as your needs evolve.

---

### Message ID: aaa279ea-48f9-490a-97e6-7c3ca08a6ca7
**Author**: user

**Content:**

now are you sure that ts files are being transpiled or transformed (whatever the term is) so they can run in this environment ? if this was running in deno, would anything need to change or would it be easier ?

---

### Message ID: eafe8dde-96f8-4724-a93f-fc2af36d6a8d
**Author**: tool

**Content:**

**Navigating TS transpilation**

I’m figuring out how to handle TypeScript files in a JavaScript environment, which seems tricky to manage directly.

**Navigating type erasure**

It's interesting to see that `importLocation` from `@endo/compartment-mapper` can manage TypeScript type erasure for `.ts` files, as long as they're outside the `node_modules` directory.

**Leveraging native support**

OK, let me see. Deno's native TypeScript support simplifies the process, eliminating the need for `@endo/compartment-mapper` and enabling `await import('https://example.com/yourModule.ts')` directly.

**Transpiling strategies**

I'm thinking through using `importLocation()` to manage `.ts` files, ensuring `languageForExtension` is set. However, type erasure might need local modifications or pre-compilation.

**Evaluating Deno's capabilities**

Deno can handle TypeScript out-of-the-box, simplifying the process. Relying on `@endo/compartment-mapper` is optional for Endo environments.

---

### Message ID: 9d924dbe-2082-4990-b9d9-bf8863f42f8e
**Author**: assistant

**Content:**

The snippet as shown does not automatically transpile or type-erase TypeScript files. Simply telling the compartment mapper that `.ts` files use the `mjs` parser with `languageForExtension` does not compile TypeScript source into plain JavaScript. By default, the `@endo/compartment-mapper` does not include a TypeScript-to-JavaScript transform step, and Node.js doesn’t support `.ts` files natively. You would need one of the following:

- Pre-compile the TypeScript code into JavaScript before using `importLocation`.
- Use a transform hook (like with `@endo/bundle-source` and `ts-blank-space`) that can do type erasure for `.ts` files.
- Provide a custom parser or translator configured via `parserForLanguage` or related compartment mapper options.

In other words, the code snippet is set up to treat `.ts` files as ESM (`mjs`), but that alone won’t run raw TypeScript. You need a step in the pipeline that converts `.ts` code to JavaScript first.

**If This Were Running in Deno:**  
Deno natively supports TypeScript and automatically transpiles `.ts` files on the fly. If you were using Deno directly (without the compartment mapper’s manual process), then you wouldn’t need these extra steps. Deno would handle the type erasure and compilation under the hood, making it far easier to run `.ts` code without additional transforms or tooling.

---

### Message ID: aaa238c5-dbc1-4b48-80e4-154bed867780
**Author**: user

**Content:**

ok so give me that code, but for running under deno.

---

### Message ID: dbaec262-faee-4aff-8db4-b59518cd279e
**Author**: tool

**Content:**

**Adapting to Deno**

I’m converting `fetch` in a Deno environment, ensuring features are implemented, and removing `node-fetch` references to avoid node-specific dependencies.

**Crafting Deno code**

I’m gathering info on using Deno's native `fetch`, adapting to no node-fetch. The code should have arrow functions, and maybe `compartment-mapper` for Deno's environment.

---

### Message ID: 1c7a8b67-f2b9-47de-9a72-ab8e802a620e
**Author**: assistant

**Content:**

```typescript
// run-remote-module.ts
// This script runs under Deno with native ESM and TypeScript support.
// It takes a URL to a .ts module, sets up a compartmentalized environment,
// and runs the module in a SES compartment.
// Usage: deno run --allow-net --allow-read run-remote-module.ts https://example.com/yourModule.ts

import 'ses';
import { importLocation } from '@endo/compartment-mapper';

// Lock down the environment
lockdown({ errorTaming: 'unsafe', stackFiltering: 'verbose' });

const loadAndRun = async (moduleURL: string): Promise<void> => {
  const packageURL = new URL('./package.json', moduleURL).toString();

  const read = async (location: string): Promise<Uint8Array> => {
    if (location === packageURL) {
      // Minimal package.json: treat all .ts files as ESM
      const pkg = {
        name: "remote-module",
        type: "module",
        main: new URL(moduleURL).pathname.replace(/^\/+/, '')
      };
      return new TextEncoder().encode(JSON.stringify(pkg));
    } else {
      const res = await fetch(location);
      if (!res.ok) {
        throw new Error(`Failed to fetch ${location}: ${res.statusText}`);
      }
      const content = await res.arrayBuffer();
      return new Uint8Array(content);
    }
  };

  // Provide limited globals
  const globals = { console };
  const modules = {};

  // Map .ts files to ESM
  const languageForExtension = { ts: 'mjs' };

  // Set import.meta.url for modules
  const importMetaHook = (specifier: string, meta: Record<string, unknown>) => {
    meta.url = specifier;
  };

  // Import the remote .ts module as if it were a local app entry point
  const { namespace } = await importLocation(read, moduleURL, {
    globals,
    modules,
    languageForExtension,
    importMetaHook,
  });

  console.log('Loaded module exports:', namespace);
};

// Run the script if called directly
if (import.meta.main) {
  const moduleURL = Deno.args[0];
  if (!moduleURL) {
    console.error('Usage: deno run --allow-net run-remote-module.ts <module_url>');
    Deno.exit(1);
  }
  await loadAndRun(moduleURL);
}
```

---

### Message ID: aaa2c028-fd2b-425b-8f07-7acf67a9a1fc
**Author**: user

**Content:**

ok, but treat the supplied url as a ts file that might have some imports in it, not as a package.json file, since this might not be the case - I want to treat the file in the url as not part of a package

---

### Message ID: 3fac13d8-4197-4d41-b932-4baac5a33cc9
**Author**: tool

**Content:**

**Mapping module loads**

I’m piecing together that Deno expects a package.json file for each module load. If dealing with unpackaged TypeScript files, creating a dummy package.json or avoiding package.json is essential.

**Navigating dependencies**

I'm considering strategies to bypass `importLocation`'s need for package.json, like using `importArchive`, `parseArchive`, or a minimal ephemeral package.json. It’s intriguing to explore these workarounds.

**Crafting minimal setups**

Considering dynamic `package.json` generation or `importArchive` for handling standalone TypeScript files. Exploring ephemeral setups is an intriguing path forward.

**Crafting an ephemeral environment**

Creating a minimal ephemeral environment for a single TS file can be achieved with `importArchive`, using a dynamically generated `package.json`. This method sidesteps the need for a pre-existing package.json.

**Building ephemeral packages**

Hmm, I’m thinking about creating minimal ephemeral packages, possibly dynamically generated, to handle single TS file imports without requiring a pre-existing package.json file.

**Piecing together the solution**

Creating a minimal ephemeral `package.json` inline for `importLocation` seems like a viable fallback, especially when handling single TS files with imports, ensuring it works without a pre-existing package.json.

**Crafting an ephemeral solution**

I'm working through providing a minimal ephemeral `package.json` for `importLocation` to address `compartment-mapper` requirements, ensuring seamless handling of single TS files without a pre-existing package.json.

**Constructing a minimal environment**

I’m considering using `compartment.import` for single TS file imports, ensuring a basic environment is set up, and dynamically creating a `package.json` from memory.

**Charting a course**

I'm delving into `importArchive` with a synthetic in-memory archive to handle single TS file imports without a pre-existing package.json, while ensuring a minimal ephemeral `package.json`.

**Crafting an ephemeral package**

OK, let me see. Exploring a minimal ephemeral `package.json` for single TS file imports to meet `compartment-mapper` needs, while treating URL as primary code without a pre-existing `package.json`.

---

### Message ID: 1d89a2a1-7416-464e-90ab-12a790dd6d68
**Author**: assistant

**Content:**

Below is a Deno-based snippet that fetches a remote `.ts` file, transpiles it to JavaScript using Deno’s built-in compiler, and runs it in a SES compartment without treating it as part of a Node-style package. It implements custom `importHook` and `resolveHook` functions to handle module imports. This approach uses the `Compartment` API directly instead of `importLocation`, so no `package.json` is needed.

**Requirements:**  
- Run with `--allow-net` so the code can fetch remote modules  
- Run with `--allow-read` if needed (for local caching or other purposes)
  
**Usage:**  
```bash
deno run --allow-net run-remote-ts-module.ts https://example.com/yourModule.ts
```

**Code:**

```typescript
// run-remote-ts-module.ts
//
// This script runs under Deno, fetches a remote TypeScript file, transpiles it to JavaScript,
// and executes it in a SES compartment. The file may have imports, which are also resolved,
// fetched, and transpiled.
//
// Usage:
// deno run --allow-net run-remote-ts-module.ts https://example.com/yourModule.ts

import 'ses';
import { ModuleSource } from '@endo/module-source';

// Lock down the environment
lockdown({ errorTaming: 'unsafe', stackFiltering: 'verbose' });

async function transpileTS(code: string, fileName: string): Promise<string> {
  const result = await Deno.transpileOnly({ [fileName]: code });
  const output = result[fileName];
  if (!output || !output.source) {
    throw new Error(`Failed to transpile ${fileName}`);
  }
  return output.source;
}

const createImportHook = () => {
  return async (specifier: string) => {
    const res = await fetch(specifier);
    if (!res.ok) {
      throw new Error(`Failed to fetch ${specifier}: ${res.statusText}`);
    }
    const sourceCode = await res.text();
    // Transpile TS to JS
    const jsCode = await transpileTS(sourceCode, specifier);
    return {
      // Provide a ModuleSource to SES
      source: new ModuleSource(jsCode, specifier),
    };
  };
};

const createResolveHook = () => {
  return (specifier: string, referrer: string) => {
    return new URL(specifier, referrer).toString();
  };
};

// Run the supplied URL in a compartment
async function runModule(entryURL: string) {
  const resolveHook = createResolveHook();
  const importHook = createImportHook();

  // Set up a compartment that can handle imports
  const compartment = new Compartment({}, {}, {
    name: 'ts-runner',
    resolveHook,
    importHook,
  });

  // Import the module and log its exports
  const ns = await compartment.import(entryURL);
  console.log('Loaded module exports:', ns);
}

if (import.meta.main) {
  const moduleURL = Deno.args[0];
  if (!moduleURL) {
    console.error('Usage: deno run --allow-net run-remote-ts-module.ts <module_url>');
    Deno.exit(1);
  }

  await runModule(moduleURL);
}
```

**What This Code Does:**

1. **Transpile:** Uses `Deno.transpileOnly()` to convert TypeScript to JavaScript on-the-fly.
2. **Fetch & Resolve:** Custom `importHook` and `resolveHook` fetch and resolve imports from URLs.
3. **SES Compartment:** Runs the resulting JavaScript code inside a hardened SES environment.
4. **No package.json Needed:** Unlike `importLocation`, this setup does not rely on any `package.json`. It directly uses `Compartment`, allowing you to treat the URL as just a single module entry point, not part of a package.

Because Deno supports fetching and transpiling `.ts` modules natively, this approach sidesteps Node-style package assumptions and leverages Deno’s built-in tooling to streamline the process.

---

### Message ID: aaa24c22-0575-43aa-a3b6-1ba3249e7277
**Author**: user

**Content:**

would it work without Deno.transpileOnly() since we are running a deno environment, so wouldn't running the ts file just work ?  or if not, can we just strip the ts rather than relying on this function, since we are running in deno deploy and might not have access ?

---

### Message ID: e1a3d481-40ad-4c77-88e1-d1465d0c9363
**Author**: tool

**Content:**

**Transpiling code**

I'm figuring out if `Deno.transpileOnly()` is needed for TypeScript code in a Deno environment with `importHook`. ESBuild or other transformers could also work.

**Evaluating methods**

I'm noting Deno's `Deno.emit()` for TypeScript to JavaScript conversion, which is stable in Deno Deploy, ensuring compatibility with SES compartments.

**Adopting Deno.emit()**

I’m inclined towards `Deno.emit()` for converting TypeScript to JavaScript, ensuring compatibility with `ModuleSource` and SES compartments. This method aligns with Deno Deploy's capabilities.

**Ensuring JS execution**

To dynamically fetch TypeScript and script evaluations at runtime, it’s crucial to transpile TypeScript to JavaScript, as SES compartments don't natively support TypeScript.

---

### Message ID: 5b50f3bb-7f74-4901-bcbf-0ab8123d095e
**Author**: assistant

**Content:**

Deno’s runtime automatically transpiles TypeScript when you use `import` statements directly, but here we're fetching the code as text and passing it to a SES `Compartment`. SES itself cannot parse TypeScript, so we must provide it with JavaScript. Without `Deno.transpileOnly()` you can use `Deno.emit()`—which is available on Deno Deploy—to transpile TypeScript on-the-fly.

Below is an updated example that uses `Deno.emit()` instead of `Deno.transpileOnly()`. It fetches a `.ts` file, transpiles it to JavaScript using Deno’s built-in compiler infrastructure, and then runs it in a SES `Compartment`.

**Important:**  
- `Deno.emit()` is stable and works on Deno Deploy.  
- Make sure to run with `--allow-net` to allow fetching modules.

**Usage:**
```bash
deno run --allow-net run-remote-ts-module.ts https://example.com/yourModule.ts
```

**Code:**
```typescript
// run-remote-ts-module.ts
//
// This script runs under Deno, fetches a remote TypeScript file, uses Deno.emit() to transpile
// it to JavaScript, and executes it in a SES compartment. The file may have imports, which are
// also resolved, fetched, and transpiled.
//
// Usage:
// deno run --allow-net run-remote-ts-module.ts https://example.com/yourModule.ts

import 'ses';
import { ModuleSource } from '@endo/module-source';

// Lock down the environment
lockdown({ errorTaming: 'unsafe', stackFiltering: 'verbose' });

async function transpileTS(code: string, fileName: string): Promise<string> {
  const { files, diagnostics } = await Deno.emit(fileName, {
    sources: { [fileName]: code },
    // Adjust compiler options as needed
    compilerOptions: {
      // Some sensible defaults for Deno TS
      target: "ES2022",
      module: "ESNext",
      strict: true,
      isolatedModules: true,
      noEmitOnError: true,
    },
  });

  if (diagnostics?.length) {
    // If there are any TypeScript diagnostics, handle them
    for (const d of diagnostics) {
      console.error(d);
    }
    throw new Error("Transpilation failed due to TypeScript diagnostics");
  }

  // `Deno.emit` puts emitted files under virtual paths like `deno:///...`
  // We need to find the correct emitted file.
  // We used `fileName` as key and expect an output keyed by a `.js` extension.
  const outFileName = Object.keys(files).find(key => key.endsWith('.js'));
  if (!outFileName) {
    throw new Error(`No JavaScript output found for ${fileName}`);
  }

  return files[outFileName];
}

const createImportHook = () => {
  return async (specifier: string) => {
    const res = await fetch(specifier);
    if (!res.ok) {
      throw new Error(`Failed to fetch ${specifier}: ${res.statusText}`);
    }
    const sourceCode = await res.text();
    // Transpile TS to JS
    const jsCode = await transpileTS(sourceCode, specifier);
    return {
      // Provide a ModuleSource to SES
      source: new ModuleSource(jsCode, specifier),
    };
  };
};

const createResolveHook = () => {
  return (specifier: string, referrer: string) => {
    return new URL(specifier, referrer).toString();
  };
};

// Run the supplied URL in a compartment
async function runModule(entryURL: string) {
  const resolveHook = createResolveHook();
  const importHook = createImportHook();

  // Provide limited globals
  const globals = { console };

  const compartment = new Compartment(globals, {}, {
    name: 'ts-runner',
    resolveHook,
    importHook,
  });

  // Import the module and log its exports
  const ns = await compartment.import(entryURL);
  console.log('Loaded module exports:', ns);
}

if (import.meta.main) {
  const moduleURL = Deno.args[0];
  if (!moduleURL) {
    console.error('Usage: deno run --allow-net run-remote-ts-module.ts <module_url>');
    Deno.exit(1);
  }

  await runModule(moduleURL);
}
```

**What This Code Does:**

- **No `Deno.transpileOnly()`:** Uses `Deno.emit()` which is available in Deno Deploy and can transpile TS to JS in-memory.
- **No package.json Needed:** It treats the fetched `.ts` code as a standalone module, resolving imports recursively.
- **SES Compartment:** Runs the JavaScript code inside a hardened SES environment, ensuring isolation.
- **Deno Native TS:** Still relies on Deno’s built-in TS compiler via `Deno.emit()`, not the runtime auto-transpilation, since we need to manually provide JavaScript to SES.

---

### Message ID: aaa2e176-d8d0-4483-9fcb-cc4b7a969631
**Author**: user

**Content:**

that's good, but instead of Deno.emit(), I want to use the library imported like "import { transpile } from 'jsr:@deno/emit'"


The docs for this library are below:

# emit

[![deno emit](https://jsr.io/badges/@deno/emit)](https://jsr.io/@deno/emit)

Transpile and bundle JavaScript and TypeScript in Deno and Deno Deploy.

> This is an unstable module, where the API is likely to change over time.

## Transpiling

Take individual modules that are JavaScript or TypeScript and emit them in a
transpiled fashion. An example of taking some TypeScript and transpiling to
JavaScript:

```ts
import { transpile } from "jsr:@deno/emit";

const url = new URL("./testdata/mod.ts", import.meta.url);
const result = await transpile(url);

const code = result.get(url.href);
console.log(code?.includes("export default function hello()"));
```

## Bundle

Take a root module and all its dependencies and emit a single JavaScript bundle.
This is similar to the functionality provided by `deno bundle` on the Deno
command line. An example:

```ts
import { bundle } from "jsr:@deno/emit";
const result = await bundle(
  new URL("https://deno.land/std@0.140.0/examples/chat/server.ts"),
);

const { code } = result;
console.log(code);
```

---

### Message ID: 7eeb2af0-d966-4dbc-88fd-74515a76b75f
**Author**: tool

**Content:**

**Transpiling Typescript**

I’m gathering info on the `transpile` method from a hypothetical library, focusing on transforming Typescript to Javascript. It returns a map of module names to their code.

**Leveraging `transpile(url)`**

I'm pushing forward with `transpile(url)` to manage fetching and transpiling in one go, making use of a URL. This should streamline the process and reduce complexity.

**Mapping the approach**

Starting with `transpile(new URL(entryURL))` to handle the entire dependency graph, and then using an `importHook` to pull code from the result map as needed.

**Streamlining the process**

Starting with `transpile` for initial fetching, followed by `importHook` to access the result map. Ensuring `importHook` uses a resolved URL specifier to retrieve code effectively.

---

### Message ID: 2d07ae87-b7f2-4279-b460-f8f8194f273a
**Author**: assistant

**Content:**

Below is a revised example that uses `transpile` from `jsr:@deno/emit`. In this scenario, we rely entirely on `transpile()` to fetch and transpile all dependencies starting from the entry URL. Then we use a custom `importHook` that simply picks the already-transpiled JavaScript code from the emitted results map. We do a one-time `transpile()` call before starting the compartment import, and cache the results for all subsequent imports.

**Requirements:**  
- Run with `--allow-net` so the code can fetch modules over the network.

**Usage:**
```bash
deno run --allow-net run-remote-ts-module.ts https://example.com/yourModule.ts
```

**Code:**
```typescript
// run-remote-ts-module.ts
//
// This script runs under Deno, uses "transpile" from "jsr:@deno/emit" to fetch and transpile
// a remote TypeScript file (and its imports) into JavaScript. It then runs the resulting code
// in a SES Compartment.
//
// Usage:
// deno run --allow-net run-remote-ts-module.ts https://example.com/yourModule.ts

import 'ses';
import { ModuleSource } from '@endo/module-source';
import { transpile } from 'jsr:@deno/emit'; // Uses the jsr:@deno/emit library

// Lock down the environment
lockdown({ errorTaming: 'unsafe', stackFiltering: 'verbose' });

async function runModule(entryURL: string) {
  // Convert the string to a URL object
  const rootURL = new URL(entryURL);

  // Transpile the entire dependency graph starting from the entry point
  const result = await transpile(rootURL);

  const resolveHook = (specifier: string, referrer: string) => {
    // Resolve relative imports
    return new URL(specifier, referrer).toString();
  };

  const importHook = async (specifier: string) => {
    // Lookup the transpiled JavaScript code from the map
    const jsCode = result.get(specifier);
    if (!jsCode) {
      throw new Error(`No transpiled code found for ${specifier}`);
    }
    return {
      source: new ModuleSource(jsCode, specifier),
    };
  };

  // Provide limited globals
  const globals = { console };

  const compartment = new Compartment(globals, {}, {
    name: 'ts-runner',
    resolveHook,
    importHook,
  });

  // Import the module and log its exports
  const ns = await compartment.import(entryURL);
  console.log('Loaded module exports:', ns);
}

if (import.meta.main) {
  const moduleURL = Deno.args[0];
  if (!moduleURL) {
    console.error('Usage: deno run --allow-net run-remote-ts-module.ts <module_url>');
    Deno.exit(1);
  }

  await runModule(moduleURL);
}
```

**What This Code Does:**

1. **Transpile with `jsr:@deno/emit`:**  
   We call `transpile(rootURL)` which fetches the entry module and all its dependencies, transpiles them to JavaScript, and returns a map of URLs to code.

2. **No Manual Fetching or Per-Module Transpiling:**  
   Since `transpile()` processes the entire dependency graph at once, the `importHook` just picks the correct code from the `result` map.

3. **SES Compartment Execution:**  
   After transpilation, the code is run in a SES `Compartment`. No `Deno.emit()` or `Deno.transpileOnly()` is needed.

4. **No `package.json` or Additional Config:**  
   We treat the remote `.ts` file purely as a standalone entry point. The `jsr:@deno/emit` library and `transpile()` handle the complexity of fetching and converting TypeScript to JavaScript behind the scenes.

---