0:00:00
Scott: Bye tomorrow, I’ll catch up at the moment.
Tom: That’s a bold claim. Tomorrow is a long way away in the distance.
Scott: The amount is a lot now. So the fun stuff, we got OpenAI doing an annoying thing calling it the 12 days of Christmas.
Tom: Ah, I saw that.
Scott: Okay, so they release O1. O1 is here now. It is the full model, polite, and smart.

0:00:38
Tom: It is everything you want in a companion. Differences between O1 and O1 Preview?
Scott: O1 Preview was slow and verbose. The new O1 is quick, polished, and efficient in reasoning. Let’s ask it something complex about scramjets and business.
Tom: Good idea, pushing it to see how it handles complexity. It’s fast.
Scott: It doesn’t produce a thousand words unnecessarily. It’s structured well. Also, there’s something about Reinforcement Learning (RL) in these 12 days of Christmas updates.

0:03:16
Tom: RL isn’t here yet?
Scott: It’s different. They released something on YouTube. Fine-tuning the model’s reasoning paths rather than just responses is key. With a few corrections, performance improves substantially.
Tom: Maybe “Agentic” ideas are out the window.
Scott: Not necessarily.
Tom: I’m skeptical about Agentic. Let’s reason about that.
Scott: GPT Pro benchmarks show O1 Pro can “grind” through reasoning. Complex tasks that took O1 10-15 seconds now extend longer. They added a progress bar.
Tom: That’s what the $200 is for. You can’t benchmark truly hard problems easily.

0:05:42
Scott: Hard problems defy benchmarks, uniqueness matters. O1 Pro is $200 a month, maybe it comes to API. Let’s get one.
Tom: Is token burn the same? $200 gives unlimited usage. This could be cheaper than API.
Scott: Great, I’ve been hammering tokens. It’s costly but maybe cheaper in bulk.

0:07:06
Tom: O1 is pricey. Maybe this is cheaper overall. We’ve been cautious using O1 due to cost.
Scott: True. I’m ill, my brain’s fuzzy, sorry.
Tom: No problem.

0:08:07
Scott: Aside from response style, does reasoning improve? I assume yes. RL suggests we can direct O1 Pro to do long reasoning sessions.
Tom: I’m skeptical. With proper prompting, maybe no big dataset needed. Why fine-tune at all if stucks (problems) are one-off?
Scott: Fine-tuning is often about style, not correctness. Devs lean toward fine-tuning. Context is key. RL can shape the reasoning process.
Tom: But with small datasets like CRM logs, can we influence the model meaningfully?
Scott: RL can help fix rare stuck cases by tweaking reasoning paths.
Tom: Perfect for one-off stucks. You don’t need huge datasets.

0:12:36
Scott: Understood. So Pro Mode and O1’s RL future sounds promising. Let’s return to the bigger picture.
Tom: The correct use of AI is to guide us. The best at that become billionaires.
Scott: Let’s consider reasoning deeply. How far can we push it? Could it run everything, from Dreamcatcher concept to daily life?

0:18:17
Tom: Reasoning is powerful. Next step: apply it to Dreamcatcher. Identify shortcomings, etc.
Scott: Also need a “talking stick.” The skill is asking good questions so when new info appears, the model responds well. Maybe GPT Pro can think for hours about Dreamcatcher’s approach or its competitors.

0:20:04
Tom: Before your illness, you used cyclic reasoning on Dreamcatcher definitions. It was good but cognitively heavy. Definitions expand then contract.
Scott: With unlimited O1 time, we can refine definitions to perfection. People use it for harder problems, so we should benefit too.
Tom: Another angle: O1 might solve things internally since it knows so much. We don’t always need to feed it more data if it already knows.

0:23:00
Scott: True, O1 knows all human knowledge. We just need to ask right questions. With O1 Pro, maybe less re-feeding.
Tom: The longer a chat, the more drift before. Maybe Pro fixes that by extended reasoning mode.
Scott: Then no need to restart threads. More stable reasoning.
Tom: If we give large context at once, O1 can self-check within its reasoning. No repeated restatements.

0:28:43
Scott: But how do we ensure definitions are good? We can’t tell until we test and render. Let’s try new tools.
Tom: Everyone with $200 can do this now. The race is on.
Scott: Should we reason about other problems? We never did “e-balance.” This still bothers me.
Tom: We have a logic layer and a process. Turning definitions into JSON and reasoning about that is sound. We can confidently do that live with stakeholders.

0:31:48
Scott: If everyone can do it, where’s our product differentiator? Reasoning alone isn’t a product.
Tom: The “stuck loop” and ambient attribution are our unique angle. Incentivized improvement loops.

0:33:40
Scott: Reasoning and O1 Pro aren’t our IP. We need value.
Tom: Capability is value. Being faster is better.
Scott: Sure, but how do we assemble it into something others don’t have?
Tom: Maybe combine with AO (some blockchain system), or create a reasoning SaaS.
Scott: Yes, a product others can consume. Ideas aren’t IP, so we must implement something tangible.

0:39:34
Tom: Let’s use reasoning to do competitive research. Package into a product.
Scott: That’s separate from building Dreamcatcher itself. We have other pieces: Naps platform, decentralized layer.
Tom: Reasoning into JSON is good. Structure first, then reason.

0:43:02
Scott: JSON and structured reasoning helps at both usage and strategy level.
Tom: Faster decisions, higher quality. AI beats humans quickly.
Scott: Humans fall behind. AO guys mirror our old ideas.
Tom: So we must deliver the “payload”: ambient attribution plus stuck loop. Need to be practical and maybe find shortcuts.

0:47:37
Scott: Let’s reason first before coding artifact to avoid being outpaced.
Tom: Exactly. Pausing to do deep reasoning with new tools might outcompete building blindly.
Scott: Attribution plus stuck loop is our unique complexity. Dreamcatcher integrates everything.
Tom: Reason Dreamcatcher out first, then decide what to implement.

0:50:05
Scott: If we reason well now, we can save time and not be trumped by someone else doing the obvious.
Tom: If it’s obvious to us, it’s obvious to others. Stuck loop might be less obvious, but no guarantee someone won’t appear with it anyway.
Scott: Our fallback is the M in attribution. It’s hard but maybe our last resort.

0:53:16
Tom: CRM work? Maybe do it quickly.
Scott: CRM guys pay, but we lose frontline progress. The tech race is fast.
Tom: Maybe integrate stuck loop into CRM for revenue.
Scott: We just need a frontend to interact with LLMs. The stuck button is crucial.

0:57:18
Tom: Customers want perfection, we want the stuck loop for improvement. Make that button special.
Scott: Many smart people chase quick wins. We try building next-gen coordination. Stuck button is key.
Tom: Not wasting time if we build that UI.
Scott: Unsure about artifact complexity, but let’s focus on reasoning first.

1:00:33
Tom: We need a reasoning tool in our platform. Then code is straightforward. Reason first, code after.
Scott: Ford’s assembly line analogy: reason before coding.
Tom: Let’s reason CRM before building.
Scott: Need reasoning about reasoning. Cursor helps a bit now.

1:04:45
Tom: Cursor sets context nicely but it’s all AI.
Scott: We need a system with definitions in files and a prompt. Possibly artifact code.
Tom: Everything can be reasoned first.
Scott: Then code emerges from that reasoning.
Tom: AI is derivative, humans look forward. Combine strengths.

1:09:28
Scott: For a cursor-like environment, we need a git-based file store. No parallel execution needed yet.
Tom: Reasoning doesn’t need parallel now.
Scott: Let’s not argue. Just build minimal parts.
Tom: Pure git store as DB.
Scott: Then single-threaded LLM with git store for CRM.
Tom: Decide domains later.

1:13:18
Scott: CRM in half a day if we choose.
Tom: But CRM clients want perfection. We want the spanner (stuck button).
Scott: Traditional apps lacked a direct fix button. Chat interface allows it.
Tom: You have 10 minutes left. Let’s finalize.
Scott: Spanner always needed, now possible with turn-based chat logic.

1:18:03
Tom: Spanner always a latent need. Chat UI surfaces it.
Scott: This leads to hyper-personalized apps.
Tom: Exactly what we want.
Scott: Stable enough now? Need some tooling. Pressing spanner, attaching context.
Tom: Working on it. Need clarity on first features.

1:21:44
Scott: First feature: parser for direct stuck. Implied stuck also defined.
Tom: How do we integrate current reasoning into the app, like talking Dreamcatcher directly in it?
Scott: If Dreamcatcher misbehaves, we talk definitions and implications.
Tom: We cycle definitions, do evals, update, improve. O1 will help.

1:23:41
Scott: Different domains (CRM, marketing, etc.) can all route through Dreamcatcher logic with the spanner.
Tom: Exactly. Changing definitions quickly gets complex; AI helps.
Scott: That’s why evals matter.
Tom: Now we’re better than before.

1:25:16
Scott: We’re closer than we think.
Tom: True.
Scott: I’ll stop recording and upload. Gotta go.
Tom: No worries, stick around if you can.
Scott: Yeah, can you…