import { z } from 'zod'

// Define the schema for content parts (text and image)
const ChatCompletionContentPartTextSchema = z.object({
  type: z.literal('text'),
  text: z.string(),
})

const ChatCompletionContentPartImageSchema = z.object({
  type: z.literal('image_url'),
  image_url: z.object({
    url: z.string(),
    detail: z.enum(['auto', 'low', 'high']).optional(),
  }),
})

const ChatCompletionContentPartRefusalSchema = z.object({
  refusal: z.string(),
  type: z.literal('refusal'),
})

const ChatCompletionContentSchema = z.union([
  z.string(),
  z.array(
    z.union([
      ChatCompletionContentPartTextSchema,
      ChatCompletionContentPartImageSchema,
    ]),
  ),
])

const ChatCompletionContentResponseSchema = z.union([
  z.string(),
  z.array(ChatCompletionContentPartTextSchema),
])

const systemMessage = z.object({
  content: ChatCompletionContentResponseSchema,
  role: z.literal('system'),
  name: z.string().optional(),
})

// Define the user message schema
const userMessage = z.object({
  content: ChatCompletionContentSchema,
  role: z.literal('user'),
  name: z.string().optional(),
})

// Define the assistant message schema
export type AssistantMessage = z.infer<
  typeof assistantMessage
>
export const assistantMessage = z.object({
  role: z.literal('assistant'),
  content: z.union([
    z.string(),
    z.array(z.union([
      ChatCompletionContentPartTextSchema,
      ChatCompletionContentPartRefusalSchema,
    ])),
  ]).optional().nullable(),
  name: z.string().optional(),
  refusal: z.string().optional().nullable(),
  tool_calls: z
    .array(
      z.object({
        id: z.string(),
        type: z.literal('function'),
        function: z.object({
          name: z.string(),
          arguments: z.string(),
        }),
      }),
    )
    .optional(),
})

export type ToolMessage = z.infer<typeof toolMessage>
const toolMessage = z.object({
  role: z.literal('tool'),
  content: ChatCompletionContentResponseSchema,
  tool_call_id: z.string(),
})

export type CompletionMessage = z.infer<typeof completionMessage>
export const completionMessage = z.union([
  systemMessage,
  userMessage,
  assistantMessage,
  toolMessage,
])

export const reasoning = z.array(z.string()).describe(
  'Step by step reasoning why this function was called and what it is trying to achieve.  This is working space for clarifying thought and is not passed through to the function',
)

export const getContent = (message: AssistantsThread['messages'][number]) => {
  const { content } = message
  if (content[0].type !== 'text') {
    throw new Error('content not text')
  }
  return content[0].text.value
}
export const getThreadPath = (pid: PID) => {
  const [, , ...actorChildBranches] = pid.branches
  const threadPath = actorChildBranches.join('/')
  const path = `threads/${threadPath}.json`
  return path
}

export const agentConfigSchema = z.object({
  model: z.enum([
    'gpt-3.5-turbo',
    'gpt-4-turbo',
    'gpt-4o',
    'gpt-4o-mini',
    'o1-preview',
    'o1-mini',
  ]),
  temperature: z.number().gte(0).lte(2).optional(),
  presence_penalty: z.number().optional(),
  tool_choice: z.enum(['auto', 'none', 'required']).optional().describe(
    'control model behaviour to force it to call a tool or no tool',
  ),
  parallel_tool_calls: z.boolean().optional().describe(
    'Is the model permitted to call more than one function at a time.  Must be false to use strict function calling',
  ),
})

export const agentSchema = z.object({
  name: z.string().regex(/^[a-zA-Z0-9_-]+$/),
  source: triad.describe('Where exactly did this agent come from'),
  description: z.string().optional(),
  config: agentConfigSchema,
  runner: z.enum(['ai-runner']),
  commands: z.array(z.string()),
  napps: z.array(z.string()),
  instructions: z.string().max(256000),
})
export type Agent = z.infer<typeof agentSchema>

export const chatParams = agentConfigSchema.extend({
  messages: z.array(completionMessage),
  seed: z.literal(1337),
  tools: z.array(z.object({
    type: z.literal('function'),
    function: z.object({
      name: z.string(),
      description: z.string().optional(),
      parameters: z.object({}).passthrough().optional(),
      strict: z.boolean().optional().nullable(),
    }),
  })).optional(),
})
export type ChatParams = z.infer<typeof chatParams>

const int = z.number().int().gte(0)

const usageSchema = z.object({
  /**
   * Number of tokens in the generated completion.
   */
  completion_tokens: int,
  /**
   * Number of tokens in the prompt.
   */
  prompt_tokens: int,
  /**
   * Total number of tokens used in the request (prompt + completion).
   */
  total_tokens: int,
  /**
   * Breakdown of tokens used in a completion.
   */
  completion_tokens_details: z.object({
    /**
     * Audio input tokens generated by the model.
     */
    audio_tokens: int.optional(),
    /**
     * Tokens generated by the model for reasoning.
     */
    reasoning_tokens: int.optional(),
  }).optional(),
  /**
   * Breakdown of tokens used in the prompt.
   */
  prompt_tokens_details: z.object({
    /**
     * Audio input tokens present in the prompt.
     */
    audio_tokens: int.optional(),
    /**
     * Cached tokens present in the prompt.
     */
    cached_tokens: int.optional(),
  }).optional(),
})

export const messageStatsSchema = z.object({
  /** The Unix timestamp (in seconds) of when the chat completion was created. */
  created: z.number().int().gte(0),
  /** The model used for the completion. */
  model: z.string(),
  /** The system fingerprint of the completion. */
  system_fingerprint: z.string(),
  /** The duration of the completion in milliseconds from our side. */
  duration: z.number().int().gte(0),
  /** The duration of the completion in milliseconds from OpenAI's side.
   */
  openAiProcessingMs: z.number().int().gte(0),
  /** The usage of the completion. */
  usage: usageSchema,
})

export const threadSchema = z.object({
  /** The current agent the conversation is with */
  agent: z.string(),
  /** The remote thread the conversation is currently with */
  remote: pidSchema.optional(),
  /** If the messages were truncated, this is the offset count */
  messageOffset: int,
  messages: z.array(completionMessage),
  toolCommits: z.record(
    /** The tool call id */
    z.string(),
    /** The commit hash the tool ended on */
    md5,
  ),
  messageStats: z.record(
    /** The message index that this stat is for */
    z.string(),
    messageStatsSchema,
  ),
  /** Have any files been changed in this threads branch */
  isDirty: z.boolean().optional(),
  summaries: z.array(
    z.object({
      title: z.string(),
      summary: z.string(),
      /** The message index that this summary starts with */
      start: z.number().int().gte(0),
      /** The message index that this summary ends with */
      end: z.number().int().gte(0).optional(),
    }).refine((data) => data.end === undefined || data.end >= data.start, {
      message: "'end' must be greater than or equal to 'start'",
      path: ['end'],
    }),
  ).optional(),
  /** History of stateboard changes */
  stateboards: z.array(z.object({
    /** What message number set the stateboard change */

    setter: int,
    commit: z.string(),
  })),
  /** History of what the focus file path was set to (like the CWD).  Allows
   * statements like "the previous file", "that other file", and "three files
   * ago"  */
  focusedFiles: z.array(z.object({
    /** The message number that set the focus */
    setter: int,
    focus: z.object({
      // Define the structure of PathTriad here
    }),
  })),
})
export type Thread = z.infer<typeof threadSchema>

export type AssistantsThread = Thread & {
  externalId: string
  messages: OpenAI.Beta.Threads.Message[]
  additionalMessages: OpenAI.Beta.Threads.RunCreateParams.AdditionalMessage[]
}
export type RemoteThread = {
  /** The location in the remote repo and the last known commit we have of it */
  triad: Triad
}
